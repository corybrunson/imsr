\documentclass[preprint, 3p,
authoryear]{elsarticle} %review=doublespace preprint=single 5p=2 column
%%% Begin My package additions %%%%%%%%%%%%%%%%%%%

\usepackage[hyphens]{url}

  \journal{Artificial Intelligence In Medicine} % Sets Journal name

\usepackage{lineno} % add
  \linenumbers % turns line numbering on

\usepackage{graphicx}
%%%%%%%%%%%%%%%% end my additions to header

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Clinical prediction with localized modeling using similarity-based cohorts: A scoping review},
            colorlinks=false,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}

\setcounter{secnumdepth}{5}
% Pandoc toggle for numbering sections (defaults to be off)


% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% From pandoc table feature
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}

% Pandoc citation processing
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
% for Pandoc 2.8 to 2.10.1
\newenvironment{cslreferences}%
  {}%
  {\par}
% For Pandoc 2.11+
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{lscape} \newcommand{\landscapebegin}{\begin{landscape}} \newcommand{\landscapeend}{\end{landscape}}



\begin{document}


\begin{frontmatter}

  \title{Clinical prediction with localized modeling using
similarity-based cohorts: A scoping review}
    \author[1]{Adi Cohen%
  %
  }
   \ead{ac4569@my.nsu.edu} 
    \author[2]{Patti McCall-Junkin%
  %
  }
   \ead{pattimccall.junkin@gmail.com} 
    \author[3]{Jason Cory Brunson%
  \corref{cor1}%
  }
   \ead{jason.brunson@medicine.ufl.edu} 
      \affiliation[1]{College of Osteopathic Medicine, Nova Southeastern
University, 3200 S University Drive, Davie, FL 33328}
    \affiliation[2]{Smathers Libraries Academic Research \& Consulting
Services, University at Florida, P. O. Box 117000, Gainesville, FL
32611-7000}
    \affiliation[3]{Laboratory for Systems Medicine, University of
Florida, P.O. Box 100225 JHMHC, Gainesville, FL 32610-0225}
    \cortext[cor1]{Corresponding author}
  
  \begin{abstract}
  Background: Applications of classical case-based reasoning (CBR) to
  clinical and health tasks have given rise to a family of techniques in
  which a statistical model is fitted to a subset of labeled cases,
  selected for relevance or similarity to an unlabeled case to which the
  model is applied. These localized models, as we propose to call them,
  may perform as well as ``black-box'' models while retaining direct
  interpretations. Their adoption has been hindered by fragmented
  development and implementation challenges. Our goal in this scoping
  review was to describe the clinical and health applications of
  localized models to date and to derive a general framework for their
  design and evaluation.

  Methods: We searched four electronic bibliographic platforms (PubMed,
  Web of Science, Academic Search Premier, and MathSciNet) during 2021
  July 19--22. We screened and reviewed entries based on four criteria
  intended to specify applications of localized models to tasks
  involving analysis of clinical or health data. Two authors divided
  title/abstract screening and collaboratively reviewed screened entries
  for inclusion. We also screened and reviewed a seed set that inspired
  the review and traced methodological citations from included entries.
  We discussed and summarized settings, tasks, and tools; identified and
  tabulated themes; and synthesized the methods into a general
  framework. We received no specific funding for this work.

  Results: Of 1,309 search results, 328 were reviewed. Of these,
  combined with 43 publications that seeded the review and 1 obtained by
  citation tracking, 25 were included in the review and methodological
  synthesis. The specificity of several search terms was poor, and
  inter-rater reliability was low. Entries were published from 1997 to
  2021, with half of these since 2015. The most common tasks were
  prognosis and diagnosis. The studies overwhelmingly focused on
  clinical data, occasionally including laboratory and image-derived
  data. Only three studies applied localized models to tasks other than
  prediction. Several studies commented on memory and runtime costs, and
  four proposed partial solutions. While few methods were reused and no
  results were reproduced, a general technique that specializes to most
  of those encountered was straightforward to describe.

  Conclusions: Localized models have potential to improve the
  performance of models used in clinical decision support tools while
  maintaining interpretability, provided computational hurdles can be
  overcome. Our search undoubtedly failed to capture all studies that
  used methods of this kind, but those we found follow a consistent
  enough design to be reproduced by a general-purpose tool. We hope that
  our review and synthesis will spur future work on efficiency,
  reproducibility, and user interactions and needs.
  \end{abstract}
    \begin{keyword}
    case-based reasoning \sep localized modeling \sep nearest
neighbors \sep clinical decision support \sep 
    scoping review
  \end{keyword}
  
 \end{frontmatter}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Clinical decision support (CDS) systems have been a fixture of
artificial intelligence (AI) research since inception. As machine
learning (ML) emerged, clinical modeling tasks became some of the most
common and celebrated applications. A technique core to clinical
applications of both AI and ML is \emph{similarity-matching}, which
relies on a \emph{patient similarity measure}\footnote{Similarity
  measures between more granular units of analysis, such as encounters
  and decision points, are often still referred to as patient similarity
  measures.} to extract a cohort of past or training cases used to
inform the diagnosis, prognosis, or care of a new or test case.
Similarity-matching powers the retrieval step of most case-based
reasoning (CBR) systems and provides the neighborhoods from which
nearest neighbor (NN) models derive predictions. Whereas NN predictions
are generated automatically via averaging (regression) or voting
(classification), traditional CBR tools return the retrieved cases to
inform human decision-making.

We discuss in this review a hybrid computational approach we call
\emph{localized modeling} (see Section \ref{sec:coherence}) that appears
to have been introduced independently several times. The approach fits
ML models, including regularized families of generalized regression
models (GLMs), to cohorts retrieved via similarity matching. Whereas CBR
and NN prediction use patient similarity to obtain an ideally
homogeneous subpopulation matched to the index case, in localized
modeling one seeks a relevant yet heterogeneous subpopulation, each
member of which may deviate from the index case. A prediction or
inference is then obtained from a model fitted to this \emph{similarity
cohort}. The use of similarity cohorts distinguishes localized modeling
from classical GLMs that still dominate analysis in clinical trials and
comparative effectiveness research, as well as from many cutting-edge ML
models that are fitted to whole populations, while the cohorts'
heterogeneity and its utility to the model distinguish the approach from
CBR. In principle, this allows interpretable models like GLMs to
identify and measure the effects of determining factors that are
specific to the index case. In the reviewed studies, localized modeling
shows some promise toward simultaneously achieving the performance
improvements of ML and the interpretability of classical models.

One memorable aspiration of clinical informatics was the ``green
button'' that would, in response to a query, automatically retrieve
patient data from an institution's records with which to conduct
on-demand retrospective studies for an individual patient {[}1{]}.
Localized modeling has recently been put forth as one answer to this
appeal. Studies using localized models have been limited by
computational cost---a naïve implementation involves fitting,
optimizing, and evaluating a model on a separate population for each
training case---and recent studies have described algorithms and
implementations designed to reduce this cost. As greater access to
health data, informatical knowledge, algorithmic efficiency, and
computational power continue to spur innovation in CDS, we may expect
localized modeling to become more accessible and efficient, its
advantages better understood, and its disadvantages ameliorated.

The motivation for this scoping review is to describe the settings in
and problems with which localized models have been tasked to date, and
to synthesize existing methods into a general framework. Along the way,
we attempt to reconcile terminology, summarize motivations and
evaluations, and propose valuable follow-up work.

\hypertarget{related-work}{%
\subsection{Related work}\label{related-work}}

Clinical CBR emerged among rule-based approaches and other AI tools in
the development of expert systems {[}2{]}. Early implementations
realized a general workflow described as ``the four REs'', later the
``R4 cycle'' {[}2,3{]}: Given a new case (or problem), the system
\emph{retrieves} one or more past cases (solved problems) from a corpus,
\emph{reuses} these to generate an understanding of (solution to) the
new case, \emph{revises} this understanding (solution) to better fit the
new case (sometimes called ``adaptation''), and \emph{retains} the new
case and its eventual understanding (solution) in the corpus to be
retrieved and reused in future. In contrast to rule-based systems, which
are variable-based and generally interpretable as a single rule applied
to all new cases, case-based systems provide case-specific
interpretations in the form of a number of more fully understood
reference cases. While the similarity measure used in the retrieval step
need not be changed as the corpus grows, proposed measures have been
diverse, contested, and rarely systematically compared.

{[}4{]} distinguished two styles of CBR: problem-solving, which is more
procedural and used when objectives are more clearly defined, and
interpretative, which provides categorizations and justifications for
possible solutions. A similar dichotomy is commonly used to distinguish
the performance criterion for the usefulness of predictive models from
the interpretability criterion for their usability. In these terms,
localized models are highly procedural: The step of fitting a predictive
model to a retrieved cohort can be understood as an automated adaptive
strategy {[}3{]}, and the parameters that govern cohort retrieval can be
tuned alongside model hyperparameters in a ML workflow. Accordingly,
localized models have been primarily used for and evaluated on their
ability to predict classes or outcomes. Nevertheless, as some recent
applications have begun to show, they can be used to draw inferences
about the importance of different risk factors to specific individuals.
While most ML models come equipped with measures of feature importance
and model-agnostic tools can generate explanations for model
predictions, these quantifications are not directly interpretable model
components analogous to the split nodes of a decision tree (DT) or the
effect estimates of a GLM. While the patient similarity measure used to
retrieve each cohort may be complicated, the cohort itself can be
directly inspected by the user. Provided the model family fitted to the
cohorts is interpretable, the localized model as a whole inherits this
property. Thus, localized models may embody both styles of CBR.

We refer the interested reader to several previous reviews of CBR in
medicine {[}3,5,6{]}, of measures of patient similarity {[}7{]}, and of
uses of patient similarity in predictive models {[}8--10{]}. While the
reviews of CBR focus on applications using health data, the patient
similarity reviews encompass many additional types of data (various
molecular -omics, genetic tests, medical images, laboratory tests,
patient preferences, patient-reported outcomes, tracking devices, social
media) and survey a much broader scope of models (exploratory analysis
via dimension reduction and cluster analysis; risk evaluation and
outcome prediction; clinical decision support and software tools). For
the present review, we are interested in how similarity matching on
patient-level health data is used to construct local cohorts for
predictive or inferential modeling.

\hypertarget{objectives}{%
\subsection{Objectives}\label{objectives}}

Our goals in this review are (1) to describe applications to date of
similarity-based localized models using patient-level health data and
(2) to provide a general framework for the design and evaluation of such
localized models. Our selection of relevant papers from the search
corpus will be based on the following inclusion/exclusion criteria:

\begin{itemize}
\tightlist
\item
  Uses case-level data from a corpus of past cases with known
  responses\newline (response may be outcome, diagnosis, subtype, etc.)
\item
  Defines a numeric multivariate case similarity measure\newline (allow
  integer-valued measures)
\item
  Uses the similarity measure to retrieve cohorts for index cases from
  the corpus\newline (for example, based on a training--testing
  partition)
\item
  Fits statistical models to cohorts from which to make predictions or
  draw inferences about index cases\newline (outcome predictions,
  survival estimates, risk factor contributions, model evaluation
  statistics, etc.)
\end{itemize}

We expected the general framework to come down to three choices: A
patient similarity measure, a cohort selection process, and a
statistical model family. Such a general method would be
straightforward, if laborious, to implement, and specializations of it
would account for the majority of real-world applications. A general
implementation based on this method would allow researchers to expedite
every step of the analysis process, including selection, optimization,
and evaluation, and enable sensitivity, robustness, and multiverse
analyses that help identify the most consequential choices along the
way.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

Here we describe our review process, including deviations from plans and
the reasons for them. More details are included in Section
\ref{sec:appendix-selection}.

\hypertarget{prisma-checklist}{%
\subsection{PRISMA checklist}\label{prisma-checklist}}

We include a PRISMA checklist as Supplemental Table 1 and a PRISMA
abstract checklist as Supplemental Table 2. Because we focus on
methodologies rather than conceptual approaches or evidence, we deviate
in some ways from PRISMA guidelines. In particular, those items of the
checklist involving bias assessment and quantitative synthesis are
intended for meta-analyses so did not apply to this study. Because we
are not aware of any standard procedures for conducting reviews and
syntheses of methodology, no protocol was prepared for this study.

\hypertarget{search}{%
\subsection{Search}\label{search}}

We derived the eligibility criteria itemized in the Introduction from a
seed set of previously read studies. Based on these criteria, we
formulated search strings for five platforms: PubMed, Web of Science,
Academic Search Premier, Google Scholar, and MathSciNet. We finalized
the PubMed search first, then adapted it to the other platforms (Section
\ref{sec:appendix-search}).

Through each platform, we searched those databases included by default.
This means that we searched both MEDLINE and PubMed Central (PMC)
through Pubmed (we did not exclude other databases, but our earliest
included results post-date them) and that we searched the six indices of
the Core Collection (the Science Citation Index Expanded, the Social
Sciences Citation Index, the Arts \& Humanities Citation Index, the
Emerging Sources Citation Index, the Conference Proceedings Citation
Index, and the Book Citation Index) as well as several regional
databases through the Web of Science platform.

The structure and terms of our search strings were inspired in part by
previous reviews adjacent to our topic of interest {[}9,10{]}. We
organized the PubMed search in disjunctive normal form (an OR of ANDs).
Following the solidification of an outline, we expanded each term to
include synonyms that are similar enough to be applicable to our search.
We then evaluated the expanded search string using the PubMed Advanced
Search platform. We initially included each term and their synonyms
separately to evaluate what resulted. We pruned several terms that
returned no results (``phrases not found'') or to reduce the number of
results. At the conclusions of this process for each individual term, we
combined the search terms using disjunctive normal form.

We conducted all searches over 2021 July 19--22. We tentatively excluded
results from Google Scholar because they were missing abstracts, and
later agreed to discard these results due to the lack of reproducibility
of the search. We organized the remaining results into a public Zotero
collection with one subcollection for each database. We then imported
the pooled results to Covidence, which merged some duplicate entries.

\hypertarget{titleabstract-screen}{%
\subsection{Title/abstract screen}\label{titleabstract-screen}}

Within Covidence, we screened titles and abstracts for relevance. We
decided on four eligibility criteria to expedite the screening process.
Articles must be written in English, for readability; they must be
original studies, to exclude secondary sources with duplicate
information; their use settings must be medical, clinical, or related,
to keep our review topical; and it must not be clear that their use of
our search terms was different from our intended meaning. Each of two
authors (AC and JCB) screened roughly half of the entries. They
regularly reviewed each other's decisions to improve consistency. In
cases of uncertainty, entries were included.

\hypertarget{full-text-review}{%
\subsection{Full text review}\label{full-text-review}}

\label{sec:full-text}

We set out 4 criteria for full-text review to restrict to studies that
used some form of localized modeling on health data:

\begin{itemize}
\tightlist
\item
  Pulls case-level data from a corpus of past cases with known classes
  or outcomes
\item
  Defines a numeric multivariate case similarity measure
\item
  Uses the similarity measure to select cohorts for index cases from the
  corpus
\item
  Fits statistical models to cohorts to make predictions or inferences
  about index cases
\end{itemize}

Note that classical CBR satisfies the first and third criteria by
definition and in most cases will satisfy the second.

In Covidence, two authors (AC and JCB) independently evaluated each
manuscript for these eligibility criteria. The first criterion that a
manuscript failed was designated the reason for exclusion. An antecedent
criterion was used to exclude manuscripts that did not report the
results of original studies involving real-world experiments or
empirical data, for example surveys of prior work and proposals of
frameworks. In cases of disagreement between the authors on the reason
for exclusion, the first criterion was adopted. The authors arrived at
agreement on inclusion or exclusion through discussion. We calculated
inter-rater reliability to evaluate our screening and review process.

During full text review, we decided to expand the conception of
statistical models (fourth criterion): Rather than restricting to models
that are fit and evaluated in separate steps, we chose to allow simple
statistical summaries such as mean survival {[}11{]} and survival curves
{[}12{]}. These approaches were novel to CBR and presage later
developments, so were helpful to understanding the development of
localized modeling. However, this then admitted studies that applied
conventional nearest neighbors prediction: Each retrieved cohort
consisted of the \(k\) most similar cases to the index case, and the
response for the index case was predicted to be either the mean
(continuous response) or the plurality (discrete response) of the
cohort's responses. A review of all studies that use nearest neighbors
prediction would be impractical. Because our focus is on novel
approaches that combine similarity-based retrieval and statistical
modeling of retrieved cohorts, we chose to exclude those studies whose
approach was equivalent to nearest neighbors prediction using a
conventional similarity measure.

Finally, one author (JCB) applied the same review process to the seed
set of 43 studies that inspired the review.

\hypertarget{coding}{%
\subsection{Coding}\label{coding}}

Following the selection sources aligning with our review, we collected
characteristics of included studies (Section \ref{sec:data}). The
features included bibliographic fields (date of publication, journal,
authors, title, keywords, DOI), study goals (objective, generalizable
knowledge, evaluation, clinical/medical domain), data sets (data source,
type of data, range of data, number of cases/incidences, number of
predictors/features), and methodological choices (types of similarity
measure, families of adaptation step/statistical model, method(s)
compared against, performance measures, results of evaluations and
comparisons, name given to modeling approach). We used these data to
detect and visualize trends amongst the included studies.

\hypertarget{synthesis}{%
\subsection{Synthesis}\label{synthesis}}

Rather than an evidence synthesis characteristic of most systematic
reviews, we here pursue a methodology synthesis to harmonize largely
independent research efforts that have converged on a common modeling
technique. The goal will be to describe a unified framework for
localized models that can be used to guide future study designs and
implementations as well as more systematically evaluate variations on
the theme and measure the dependence of results on modeling choices.

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{selection}{%
\subsection{Selection}\label{selection}}

Figure \ref{fig:prisma} depicts our identification of studies via
databases and registers. Following the completion and input of each
search string, there were a total of 1,422 sources within all of the
platforms used. De-duplication resulted in 1,309 entries, which were
added to the title/abstract screening for review. Of these, 328 entries
met the screening criteria and were assessed through full text review.
Of these, 44 fit the original criteria, and 19 were included as distinct
from NN prediction.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../../fig/fig-prisma} 

}

\caption{\label{fig:prisma}PRISMA-S flow chart. Lowercase letters refer to items obtained from the seed set (m), the structured search (n), and citation/reference tracking (s).}\label{fig:fig:prisma}
\end{figure}

There were 60 disagreements over inclusion versus exclusion. Inter-rater
reliability was low, at 82\% relative to a 72\% probability of random
agreement.

We then reviewed 43 studies comprising a seed set that inspired this
review. After removing duplicates and screening for eligibility, we were
left with 6 additional studies {[}12--17{]}, 1 of which was excluded
from the synthesis for using NN prediction. Finally, reference tracking
from the 43 + 328 = 371 studies assessed for eligibility led us to
identify 1 additional study that met our criteria {[}18{]}. This left us
with 19 + 1 + 5 = 25 studies included in the review and synthesis.

\hypertarget{bibliographic-and-methodological-properties}{%
\subsection{Bibliographic and methodological
properties}\label{bibliographic-and-methodological-properties}}

The 25 included studies were analyzed based on 20 characteristics (see
Section \ref{sec:data}), and we report and describe some observations
here (Table \ref{tab:synthesis}). The studies were published in a
variety of journals, with some of greater frequency, though no single
journal published more than 3. The journal \emph{Evolving Systems}
published 2 of the included studies, \emph{Artificial Intelligence in
Medicine} published 3, \emph{Hindawi - Journal of Healthcare
Engineering} published 3, and \emph{PLOS One} published 2.

Another interesting pattern lay in the years of publication (Figure
\ref{fig:year}). While they trace back to the late 1990s, they have
become more common, which suggests that this is an active, though not
rapidly expanding, methodological approach. We note that, while CBR in
health and medicine originated as early as 1990, these studies did
emerge early on once CBR had established itself. So the idea has been
``in the air'' for as long as CBR has been in use.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1215}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1602}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1215}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1823}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1547}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1050}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1547}}@{}}
\caption{\label{tab:synthesis}Studies included in the method synthesis,
arranged by the earliest the study is known to have been
public.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Citation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Aim
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Cases
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Features
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Citation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Aim
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Source
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Cases
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Features
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}19{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 1,355 & 9 \\
{[}11{]} & Prognosis\hspace{6em} & Knowledge\hspace{6em} &
Clinical\hspace{6em} & Longitudinal\hspace{6em} & 113 & 4 \\
{[}20{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Laboratory\hspace{6em} & Cross-sectional\hspace{6em} & 160 & 14 \\
{[}13{]} & Diagnosis\hspace{6em} & Practice\hspace{6em} & Clinical,
Imaging\hspace{6em} & Cross-sectional\hspace{6em} & 366; 270; 560; 760 &
35; 14; 31; 8 \\
{[}21{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 1,000; 447 & 6;
6 \\
{[}22{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 2,620 & 6 \\
{[}23{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 67 & 14 \\
{[}24{]} & Diagnosis\hspace{6em} & Knowledge\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 871 & 4 \\
{[}18{]} & Diagnosis\hspace{6em} & Knowledge\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 62 & 2,000 \\
{[}25{]} & Decision Support\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 74 & 93 \\
{[}26{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 62; 72; 77; 181 &
2,000; 7,129; 7,129; 12,533 \\
{[}12{]} & Prediction\hspace{6em} & Practice\hspace{6em} & Clinical,
Laboratory\hspace{6em} & Longitudinal\hspace{6em} & 13,525 & 13 \\
{[}27{]} & Decision Support\hspace{6em} & Practice\hspace{6em} &
Patient-reported\hspace{6em} & Cross-sectional\hspace{6em} & 1,647 &
18 \\
{[}28{]} & Diagnosis\hspace{6em} & Knowledge\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 150 & 83 \\
{[}15{]} & Clustering\hspace{6em} & Practice\hspace{6em} & Clinical,
Laboratory\hspace{6em} & Longitudinal\hspace{6em} & 7,519 & 130 \\
{[}14{]} & Prediction\hspace{6em} & Knowledge\hspace{6em} & Clinical,
Laboratory\hspace{6em} & Cross-sectional\hspace{6em} & 17,152 & 75 \\
{[}29{]} & Diagnosis\hspace{6em} & Knowledge\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 1,046 & 8 \\
{[}16{]} & Prediction\hspace{6em} & Practice\hspace{6em} & Clinical,
Laboratory\hspace{6em} & Cross-sectional\hspace{6em} & 17,152 & 75 \\
{[}30{]} & Diagnosis\hspace{6em} & Knowledge\hspace{6em} &
Imaging\hspace{6em} & Cross-sectional\hspace{6em} & 810; 302 & 8 \\
{[}31{]} & Decision Support\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 638 & 49,728 \\
{[}32{]} & Prediction\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 4,000 & 22 \\
{[}17{]} & Diagnosis\hspace{6em} & Practice\hspace{6em} & Clinical,
Laboratory\hspace{6em} & Cross-sectional\hspace{6em} & 16,490 & 106 \\
{[}33{]} & Decision Support\hspace{6em} & Practice\hspace{6em} &
Clinical\hspace{6em} & Cross-sectional\hspace{6em} & 8 & 5 \\
{[}34{]}; {[}35{]} & Decision Support\hspace{6em} & Practice\hspace{6em}
& Clinical\hspace{6em} & Longitudinal\hspace{6em} & 245,825 &
1,466,474 \\
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{../../fig/fig-years} 

}

\caption{\label{fig:year}Number of publications in our sample each year.}\label{fig:fig:year}
\end{figure}

Another dominant characteristic of included studies is their broader
remit. We categorized studies as ``knowledge'' or ``practice'' based on
whether their aim was to produce generalizable knowledge or to improve
practice. We classified 7 of the 25 studies as ``knowledge'', making the
majority of studies from a ``practice'' standpoint. These studies aimed
to provide tools for use in clinic or to improve outcomes.

Lastly, we observed a commonality among 6 of the 25 included studies in
having evaluated methods using leave-one-out cross-validation (LOOCV).
The purpose of this measure is to estimate the overall performance of
certain factors when used to make predictions, particularly utilized on
smaller data sets, where models benefit greatly from larger training
sets and additional model fitting is less costly.

In addition to the aim of its analysis, we coded several aspects of the
design of each study, including the source and type of data and the
clinical task the model performed (Table \ref{tab:synthesis}), as well
as the specific methodology and terminology adopted (Table
\ref{tab:composite}). In the following subsections, we take a closer
look at these design elements.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1128}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4410}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4462}}@{}}
\caption{\label{tab:composite}Methodological elements of studies
included in the synthesis.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Citation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Elements
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Terminology
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Citation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Elements
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Terminology
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}19{]} & supervised similarity learning & CBR; case-structured
retrieval \\
{[}11{]} & predictive modeling on similarity cohorts & CBR; targeted
subsampling \\
{[}20{]} & unsupervised similarity learning & Combined Kohonen type
neural network-case-based reasoning \\
{[}13{]} & supervised cohort construction & CBR, statistical case-based
reasoning \\
{[}21{]} & supervised similarity learning & Transductive inference \\
{[}22{]} & unsupervised similarity learning & CBR; entropic distance
measure \\
{[}23{]} & tiered constraint; similarity matching & CBR \\
{[}24{]} & interactive implementation & CBR; eXiT*CBR \\
{[}18{]} & predictive modeling on similarity cohorts & Personalized
model \\
{[}25{]} & predictive modeling on similarity cohorts & Personalized
modeling; TWNFI \\
{[}26{]} & predictive modeling on similarity cohorts & Local modeling;
personalized modeling; TWNFI \\
{[}12{]} & predictive modeling on similarity cohorts & K-nearest
neighbors survival \\
{[}27{]} & supervised similarity learning & CBR \\
{[}28{]} & supervised similarity learning & CBR \\
{[}15{]} & predictive modeling on similarity cohorts; explanatory
modeling on similarity cohorts & Personalized predictive model \\
{[}14{]} & predictive modeling on similarity cohorts & Personalized
prediction \\
{[}29{]} & supervised similarity learning; predictive modeling on
similarity cohorts & CBR \\
{[}16{]} & predictive modeling on similarity cohorts & Patient-specific
predictive model \\
{[}30{]} & whole-population weight learning & Gaussian processes \\
{[}31{]} & unclear & CBR \\
{[}32{]} & predictive modeling on similarity cohorts & Personalized
model \\
{[}17{]} & predictive modeling on similarity cohorts & Personalized
predictive modeling \\
{[}33{]} & descriptive modeling on similarity cohorts & CBR \\
{[}34{]}; {[}35{]} & supervised similarity learning; predictive modeling
on similarity cohorts & Similarity model, personalized model, precision
cohort, personalized treatment options \\
\end{longtable}

\hypertarget{application-domains}{%
\subsection{Application domains}\label{application-domains}}

While all included studies were reported in scientific and medical
journals, the vast majority were oriented toward clinical practice
rather than medical research. For example, a 2006 study specifically
evaluated the usefulness of CBR-based explanations for the purpose of
decision support {[}36{]}. This study was part of a much larger
literature on CBR systems and was included here despite relying on NN
prediction because it used an unconventional voting scheme to generate
recommendations. A more recent study took essentially the same focus
with respect to a proposed clinical risk prediction model, which
amounted to CBR with a novel weighting scheme on predictors informed by
expert consensus {[}37{]}. In both cases a prototype implementation was
deployed in an experimental setting for evaluation.

The most common clinical motivations were individualized detection or
diagnosis, prognosis or outcome prediction, and treatment or care
recommendation. The plurality focused on prognosis or outcome
prediction, often using time-to-event analysis: {[}11{]} used CBR to
predict survival time from several geometric properties of breast
tumors. {[}12{]} used CBR with non-parametric survival models on
registry data to predict patient--graft survival times following kidney
transplantation. {[}14{]} and {[}16{]} used localized logistic
regression and random forest modeling to predict 30-day mortality
following discharge for ICU patients. {[}29{]} developed a CBR cycle
around a clustering-informed similarity matching procedure and an
artificial neural network--based classifier to identify thrombophilia
patients at high risk of thrombotic episodes. And {[}32{]} took a
similarity cohort--based approach to predicting length of stay for ICU
patients. Also of note, from a public health perspective, {[}23{]} used
CBR to predict rehabilitation time as well as disability risk for
unemployed workers experiencing chronic pain.

Toward detection and diagnosis, {[}20{]} proposed a hybrid neural
net--CBR system to distinguish (with confidence bounds) arthritic versus
control patients, based on several histological features. {[}28{]} used
collaborative multilabel CBR to subtype melanoma patients based on
confocal and dermoscopy images. {[}17{]} used localized models built
from a multi-type additive similarity measure to distinguish type 2
diabetic versus control populations. Along the way, {[}21{]}, {[}18{]},
and {[}25{]} took an iterative model-building approach to several tasks:
predicting glomerular filtration rate, a key indicator of renal
function, from demographic and physiological variables; identifying
patients with colon cancer using a large number of gene expression
measurements; and identifying patients with type 2 diabetes based on
demographic, physiological, and genetic variables.

While several studies emphasized the potential or actual value to
decision-making of their methods and tools, only one incorporated
treatment decisions into their approach: By taking ``decision points''
as their units of analysis, {[}34{]} and {[}35{]} built not classifiers
or predictors but comparative effectiveness models into a localized
framework, providing for the first time in our sample explicitly
prescriptive rather than descriptive clinical decision support.

A partial exception to this focus was a 2014 study that also reported a
decision support tool, in this case for early diagnosis of melanoma from
clinical data and dermoscopy images {[}28{]}. While the stated
objectives were analogous, specific emphasis was placed on the
acquisition of new knowledge through the development of the tool,
including the systematic generation of new data and creation of a
clinical ontology. This study was included for its use of a
collaborative classifier that drew from multiple modeling approaches. In
keeping with this focus of the included literature, the stated
objectives of the proposed methods were more often (or additionally) to
predict outcomes or to recommend interventions than only to diagnose
disease.

The mosaic plot in Figure \ref{fig:properties} summarizes the relation
between data source, clinical task, and aim.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../../fig/fig-properties} 

}

\caption{\label{fig:properties}Share of studies characterized by several design elements: data source (row), clinical task (fill color), and remit (opacity).}\label{fig:fig:properties}
\end{figure}

\hypertarget{rationales}{%
\subsection{Rationales}\label{rationales}}

\label{sec:rationales}

The included studies hypothesized, asserted, or assumed several benefits
of localized modeling specific to clinical and medical settings and
advantages over other modeling approaches (see Section \ref{sec:data}).
The most common was that the restriction to similar or relevant past
cases would improve predictive performance for the index case
{[}11,15,16,26{]}. In particular, {[}14{]} hypothesized and confirmed
that the value of each past case would be positively related to its
similarity to the index case, an assumption built in to the weighting
schemes of other approaches. {[}12{]} made a different case, that the
fewer parametric assumptions and complications of a CBR-style model
would allow for greater accuracy. Additionally, several investigators
asserted that the use of localized cohorts befit the clinical focus on
the individual patient rather than the population, without reference to
performance {[}21,23{]}.

In an interesting contrast, {[}34{]} and {[}35{]} argued that their
localized approach using the larger and more heterogeneous populations
covered by EHR-derived data could better capture the messy and diverse
lessons of everyday practice, as a counterpart to guidelines based on
randomized controlled trials. Their emphasis on the enabling role of
EHRs to power methods well-suited to large, structured data repositories
was shared by several others {[}16,25,27,28{]}. {[}25{]} and {[}30{]}
additionally pointed out that localized models are adaptable to noise in
the data, variation in patterns of missingness, and (harkening to the
last step of the R4 cycle) addition of new cases with known outcomes to
the corpus. These properties, they said, tend to be more difficult for
whole-population models to handle.

The other frequent advantage attributed to localized modeling was
interpretability. {[}22{]} and {[}28{]} emphasized the value of the
detailed past cases, available to the user, on which predictions are
based. This ``self-explanation capability'' made outputs more
intelligible to physicians in the CDS setting. {[}15{]} additionally
pointed out that localized GLMs yield localized effect estimates, which
may help investigators identify individually relevant risk factors.

The remaining coded rationales were for augmentations or hybridizations
of then-conventional CBR, most of which defended the use of other tools
to improve performance via cohort selection {[}27--29{]} or to make
models and outputs more interpretable {[}17,24{]}. {[}26{]} argued for
simultaneous optimization of cohort and feature selection with model
parameterization; their TWNFI approach combines localization with
regularization.

\hypertarget{challenges}{%
\subsection{Challenges}\label{challenges}}

CBR can be understood as the opposite side of a trade-off with
rule-based reasoning between model size and model complexity; {[}36{]}
describe their approach as ``knowledge-light'', in that ``the cases do
not contain explicit explanation structures; instead, explanation is
achieved by comparison of the query case with retrieved cases''. This
means that the greatest performance and efficiency challenges in CBR
have to do with the retrieval and revision phases in the R4 cycle.
Several studies addressed these challenges: {[}13{]}, while excluded
from the synthesis, were the earliest to propose that cohorts be bounded
by a similarity threshold rather than by a number of cases, and this
improved performance in their experiments. {[}38{]} leveraged predictor
weights obtained from logistic regression to inform the similarity
calculation used in retrieval. {[}12{]} used non-parametric models to
reduce the computational burden of revision (prediction). {[}32{]}
proposed to improve efficiency along the entire R4 cycle, but in
particular by only executing task-dependent steps in real time
(``just-in-time learning'', JITL), and {[}35{]} and {[}34{]} partitioned
multiple phases in the R4 cycle into offline and online components, only
the latter of which would be performed in real time as new data are
received.

Other studies addressed limitations of available tools. {[}24{]}
implemented a comprehensive CBR tool in response to the lack of
general-purpose software, to enable coupling with other tools as well as
to expedite development, experimentation, and uptake. Several other
teams also set out to develop more interoperable clinical support tools
{[}15,22,26,30{]}. The frequency plot in Figure \ref{fig:methods}
compares the rates at which several methodological elements are invoked
in the sample.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{../../fig/fig-methods} 

}

\caption{\label{fig:methods}Frequency of recurring methodological elements across included studies.}\label{fig:fig:methods}
\end{figure}

\hypertarget{performance-assessments}{%
\subsection{Performance assessments}\label{performance-assessments}}

\label{sec:performance}

Most included studies quantitatively compared the predictive performance
of their proposed method(s) to one or more comparators. What we took to
be the signature results are collated in Table \ref{tab:performance} in
the Appendix. Note that we exercised some judgment in classifying
methods as proposals and comparators, as in some cases all methods were
original but only some showcased main ideas. It would be impractical to
meta-analyze these numbers due to the great variety of settings,
problems, data types, and choices involved.

We do observe one clear pattern: All of the proposed methods that most
evidently outperformed their comparators (Kohonen + CBR {[}20{]}, TWNFI
{[}18{]}, gravitational search algorithms (GSA) {[}26{]}, CBR + rules (+
DML) {[}28{]}, Gaussian process regression {[}30{]}, JITL-ELM {[}32{]})
are hybrids of localized modeling (in some cases CBR) with other
techniques, often DML. Though {[}27{]} and {[}15{]} report non-superior
performance by such hybrids, the pattern suggests the importance of the
similarity measure to the retrieval step. Meanwhile, when proposed
approaches targeted cohort demarcation or choice of predictive model
(statistical CBR {[}13{]}; individualized logistic regression, decision
tree, and random forest {[}14,16{]}), they did not consistently
outperform comparators.

\hypertarget{identified-needs}{%
\subsection{Identified needs}\label{identified-needs}}

\label{sec:needs}

The study authors focused their recommendations and their own plans for
future work mostly on technical improvements and evaluations
{[}11,19{]}. Urged improvements included full or partial automation of
predictor selection {[}11,19{]}, similarity learning {[}11,17{]}, and
parameter optimization {[}16,21{]}; extensions to new data structures
{[}24{]}, data types {[}25,26,31{]}, and reasoning systems {[}28{]}; and
the use of more advanced model components to improve accuracy or
efficiency {[}12,14,26,30{]}. Authors also urged validations and
independent evaluations using larger or more comprehensive data sets
{[}15,22,23,25{]}, using data aggregated from multiple health systems
{[}14,16,34,35{]}, and in other care settings or disease contexts
{[}21,30,34,35{]}.

Less common were calls to strengthen the connection between the methods
and the users. Some authors urged the incorporation of (human-derived)
domain knowledge into the data or models {[}17,19{]}. Others suggested
new uses of their modeling approaches: to measure feature importance
{[}20{]}, to make models more expressive {[}14{]}, and to combine
information obtained both from global and from localized models
{[}15{]}. Most of this incremental work was indeed carried out in later
investigations in our sample.

\hypertarget{reproducibility}{%
\subsection{Reproducibility}\label{reproducibility}}

\label{sec:reproducibility}

\textbf{Discuss public availability of code or implementations.}
\textbf{Methods, results, and inferential reproducibility {[}39{]}.}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

After commenting briefly on our review process, we draw several
observations from our encoding of the included studies. We first focus
on their methodological choices and innovations, then on their
conventions and language. We spend most of the section discussing the
differences and commonalities of the techniques used, toward a general
method that encompasses most or all cases. We then suggest some avenues
for future studies and conclude with our key takeaways.

\hypertarget{process}{%
\subsection{Process}\label{process}}

The low inter-rater reliability was due, in parts, to different
interpretations of some eligibility criteria by the authors,
inconsistent terminology across the sample, and incomplete reporting of
resources and methods in the sample. Regarding interpretation of
criteria, some wording of the criteria was adjusted following
discussions between the reviewing authors during full-text review to
better specify an agreed-upon meaning. We will discuss the different
domains, terminologies, and reporting issues of the sample in the
remainder of this section.

\hypertarget{study-designs}{%
\subsection{Study designs}\label{study-designs}}

Consistent with their orientation, almost all included studies were
conducted using clinical data, only occasionally together with
patient-reported (2), laboratory (2), and image (1) data. We suggest
three reasons for this: First, this literature traces back to the 1990s,
before -omic data could be generated cost-effectively at scale. Second,
CBR in particular has a strong tradition in clinical decision support,
where the focus of our sample remains throughout the review period.
Third, because most -omic data are highly homogeneous---all measurements
are made along or can be transformed to a common scale, e.g.~greyscale
pixellations for X-ray images and transcripts per million for RNA-seq
data---more deeply theoretical analysis techniques have been developed
and come into wide use. While variations on correlation-based approaches
like EHR-based phenome-wide association studies and similarity-based
methods like CBR itself have been developed, more mechanistic and
probabilistic tools have not become a domain standard.

Because we excluded studies that used conventional NN prediction, many
included studies reported new approaches to adaptation subsequent to
retrieval. Very few proposed novel similarity measures, possibly because
larger studies tended to be reported in separate articles detailing
experiments with specific components of the process. However, this also
suggests that few experimental studies have focused on the unified
development of new retrieval and adaptation strategies. We also note
that the majority of studies evaluated and compared methods using
leave-one-out cross-validation (LOOCV). This is an especially
appropriate technique when available data are scarce, and indeed most
data sets used by included studies numbered in the hundreds of cases or
fewer. This likely follows from the older age of many included studies
and from their consistent primary focus on clinical data, which is more
costly to collect and comes with more restrictions on its use.

\hypertarget{coherence}{%
\subsection{Coherence}\label{coherence}}

\label{sec:coherence}

The motivational and methodological unity of these studies does not
reflect a unified research program. Besides the lack of any primary
journal of record, we observed collaborations only among the authors of
smaller contiguous programs, including applications of the TWNFI
methodology {[}21,25{]}, individualized mortality prediction for ICU
patients {[}14,16{]} and the use of more explanatory models to
prioritize predictors or treatments for chronic disease {[}15,34,35{]}.

These programs used varying terminology for common concepts, and no
common term is in use for what we here refer to as localized modeling;
authors described their approaches as ``targeted prognosis'' {[}11{]},
``transductive inference'' {[}21{]}, ``personalized decision support''
{[}14{]}, ``personalized (predictive) models'' {[}26, in contrast to
``local models,''15,17,32{]}, and ``precision cohort'' analysis
{[}17,34,35{]}. We find uses of ``targeted'', ``personalized'', and
``precision'' generic and imprecise to this approach, while transductive
inference is an established term for a broader set of methods in ML.
Because \emph{local} naturally contrasts with \emph{global}, we propose
``localized models'' as a suitable term for this counterpart to
globally-fitted models.\footnote{We note, in response to one reviewer's
  comment, that for many if not most models used in ML, excepting GLMs,
  a predictor may play a different and more or less important role for
  some cases than others, as quantified by importance measures or
  model-agnostic explanations {[}40,41{]}. In this way, such models can
  also be viewed as ``localized''. We recognize that the use of global
  and local explanations is standard. As another reviewer pointed out,
  the terminology of local and global is also used in the unrelated
  context of federated ML to distinguish models trained using data
  stored in a single storage device (local) from their aggregations
  (global) {[}42,43{]}. The prospects for federated architecture to more
  effectively implement similarity cohort--based models are intriguing,
  and would require some reconciliation of terms. At present, we feel
  that these methods are sufficiently disjoint to avoid confusion in
  practice, but we suggest the more specific term ``similarity
  cohort--based models'' when the term ``local'' is overloaded.}

\hypertarget{synthesis-1}{%
\subsection{Synthesis}\label{synthesis-1}}

The 25 studies included in our synthesis used composite techniques that
we organized into two major types. One type, \emph{similarity learning},
was used in 8 studies that tie in to the much larger literature on DML
{[}44{]}. The other, \emph{cohort thresholding}, focused on choosing or
optimizing the manner in which cohorts were demarcated using the
similarity measure.

\hypertarget{similarity-learning-and-threshold-optimization}{%
\subsubsection{Similarity learning and threshold
optimization}\label{similarity-learning-and-threshold-optimization}}

The similarity learning approaches took a variety of forms. These
techniques are designed to detect structure in data, especially
associations between predictors and responses, and to use this structure
to inform the definition of a patient similarity measure. Seven studies
used response values in training data sets to supervise similarity
learning while two used unsupervised learning (Table
\ref{tab:composite}). Based on the key properties of DML algorithms
identified by {[}45{]}, most learned measures were non-linear while some
were locally learned, and some were optimized globally while others
locally. Not all qualified as DML, since the resulting measures would
not necessarily satisfy the triangle inequality. Each used its
similarity measure to retrieve training cases relevant to each testing
case. Once retrieved, most took a standard NN approach to generating
predictions; two exceptions {[}29,34{]} fit predictive models to the
retrieved cohorts.

Several studies used unsupervised similarity learning, for example the
Mahalanobis distance {[}12{]} and the Kolmogorov entropy-based distance
{[}22{]}. In particular, {[}19{]} defined similarity as a weighted sum
of differences in predictor values and used linear regression to
optimize the weights for the predictive accuracy of the cohort they
retrieve. Others used supervised learning: {[}21{]} proposed an
iterative algorithm to optimize a set of fuzzy inference rules used to
retrieve relevant cases and generate a prediction, using
back-propagation on the rules' parameters. Their method was used in
several later studies returned by our search, which are not discussed
here because they did not originate the technique. {[}28{]} explicitly
appeal to a supervised distance metric learning (DML) technique {[}46{]}
to obtain a similarity measure on their set of dermoscopy and confocal
images that most effectively separates malignant from benign melanoma
tumors. We will discuss the remaining uses of supervised similarity
learning shortly.

Distinct from but related to similarity learning was supervised cohort
construction. This was an adaptive step taken by {[}13{]} to optimize
the predictive performance of models fitted to cohorts retrieved using a
fixed similarity rather than count threshold, a counterpart to
conventional CBR they called ``statistical CBR''.\footnote{Drawing from
  {[}47{]}, we suggest the term ``combinatorial CBR'' for the
  then-conventional approach using similarity cohorts of fixed
  cardinality.} The step used a heuristic procedure to locate a
similarity threshold that (locally) maximizes predictive accuracy on the
training set. This is analogous to optimizing the neighborhood size
parameter in NN predictive modeling, so we will not discuss it further
except to mention that the authors found statistical CBR to outperform
conventional CBR on several data sets. {[}27{]} combined these learning
techniques: They used logistic regression on the training set to obtain
weights for the predictors (by predicting the binary outcome of kidney
transplant waitlist registration) and for the cases (by predicting
agreement of outcome between an index case and other training cases),
and they used exhaustion to optimize the size of the retrieved cohort
for the accuracy of the NN model using the previously optimized weights.

As noted above, these instances of similarity learning fit into a much
larger literature on DML, which has seen widespread use in health
informatics and modeling. That these studies satisfied our review
criteria is due to the novelty of the techniques at the time of
publication and the detailed attention paid to their techniques by the
authors. It also reflects a limitation of our study and of the
literature we set out to retrieve: We are aware of no standard terms in
use to identify the family of techniques that fit statistical models to
similarity-based cohorts. The retrieved studies whose use of such
techniques alone satisfied our criteria variably termed them
individualized, personalized, local, and patient-specific models, among
other terms (Table \ref{tab:composite}). We prefer the term localized
models, which is both sensitive and specific to uses of a similarity or
distance measure to retrieve a cohort to which a model is fit: It
includes some properly included techniques we did not have in mind
{[}29{]} yet excludes other techniques commonly referred to as
individualized, personalized, or precision.

\hypertarget{localized-models}{%
\subsubsection{Localized models}\label{localized-models}}

In addition to {[}12{]}, {[}26{]}, {[}15{]}, {[}16{]}, {[}29{]},
{[}34{]}, and {[}35{]}, five other studies employed localized models:
{[}11{]}, {[}14{]}, {[}25{]}, {[}17{]}, and {[}32{]}. In most cases
these models were purely predictive in application; of the exceptions,
{[}11{]} produced purely descriptive models of survival outcomes, which
were evaluated for their precision rather than their accuracy, while
{[}15{]} used generalized regression models descriptively as well as
predictively, as did some of the same authors {[}34,35{]} later. The
most common approach to cohort selection was to optimize a size
threshold via manual exploration {[}11,14--17,29{]} or via
cross-validation {[}12,25{]}. Further in the former direction, one study
{[}32{]} set a fixed cohort size while two {[}26,34,35{]} devised more
sophisticated algorithms to balance multiple desiderata including
predictive accuracy.

Several themes emerged from this sample. Foremost was the optimization
of retrieved cohort sizes for some measure of model performance. Despite
the early recommendation by {[}13{]} to threshold cohorts by similarity
rather than by cardinality, only the one previously published study
{[}11{]} and the most recent study {[}34,35{]} in this corpus took this
approach. Viewed as a hyperparameter of the individualized modeling
approach, cohort size can be treated in the same way as neighborhood
size in NN prediction (viewed here as a special case of localized
modeling wherein the model is a simple summary statistic), so we will
not discuss it further.

An alternative approach was to optimize multiple hyperparameters
together: {[}18{]} proposed an iterative algorithm to settle on an
optimal number and set of predictors as well as number of training cases
(comprising the retrieved cohort) that was later used by {[}26{]}. More
recently, {[}34{]} and {[}35{]} proposed a three-step process for cohort
selection that filtered by exact match for one subset of predictors,
used domain-informed similarity measures to rank these, and optimized
the similarity threshold for a trade-off between cohort size and a
measure of bias called cohort balance. Notably, though their similarity
measure was supervised, this optimization process was not.

With the exception of the descriptive survival models of {[}11{]}, only
one thread in this corpus concerned itself with the interpretability of
localized models: {[}15{]} fit logistic regression models to
similarity-based cohorts and examined not only their predictive
performance but the localized sets of largest and most detectable
predictors, termed risk profiles, and how they differed across the
testing population. This approach informed their later use of localized
comparative effectiveness--style models to recommend courses of
treatment at decision points during a monitored patent's stay
{[}34,35{]}. These studies suggest much wider potential for localized
real-world evidence generation, which has long been promoted as a
promise of advances in clinical and health informatics {[}1{]}.

\hypertarget{a-general-framework}{%
\subsubsection{A general framework}\label{a-general-framework}}

This relatively small sample exhibited a wide range of approaches, both
technically and conceptually. Discussion of the technical diversity of
these approaches has been summarized above and published in greater
detail in previous reviews {[}6,9,10{]}, and we focus here on the
conceptual. The design of a localized modeling approach can be
decomposed into three largely independent choices: (1) how to measure
the similarity between cases, (2) how to retrieve a cohort of cases
similar to an index case, and (3) how to generate a prediction or other
statistical insight for the index case from the similarity cohort. The
choices are the \emph{similarity measure}, the \emph{cohort retrieval},
and the \emph{statistical model}, respectively. These are diagrammed in
Figure \ref{fig:framework}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../../fig/fig-typology} 

}

\caption{\label{fig:framework}General framework for localized models.}\label{fig:fig:framework}
\end{figure}

Each step can be unsupervised supervised: Unsupervised similarity
measures include discrete measures like the Levenshtein distance and
continuous measures like cosine similarity, while supervised measures
include the Mahalanobis distance and random forest proximity as well as
several composite measures with weights calculated from the data. Most
retrieval steps obtained cohorts with a uniform size (cardinality) or
similarity threshold, and the remaining were likewise only informed by
predictors; thus, while a retrieval step could in principle be
supervised, in this sample none were. Almost all models were supervised,
being that most performed predictive tasks, though {[}11{]} modeled only
survival rates within localized cohorts. Meanwhile, each step can be
optimized in a ML fashion by having its parameters tuned to improve
performance. We found no studies that tuned the calculation of
similarity, though most uniform cohort sizes were tuned. Some earlier
studies tuned generalized regression models, but more recent studies did
not.

\hypertarget{directions-and-expectations}{%
\subsection{Directions and
expectations}\label{directions-and-expectations}}

As discussed in Section \ref{sec:rationales}, most studies were premised
on the potential predictive value of localized models. As cautioned in
Section \ref{sec:performance}, not all experiments affirmed this
premise. Most of those that did involved using metric learning to
improve retrieval and sometimes iterative optimization of the metric and
of the localized model. Some studies showcased results using a variety
of such specializations {[}15,27,30{]}. However, because these advanced
implementations were mostly compared against their precursors or
commonplace alternatives, we cannot speak to their performance or any
trade-offs with respect to each other. This would be a worthy goal of
future work, though it might be limited by the lack of open-source code
or public implementations (Section \ref{sec:reproducibility}).

While most studies identified outstanding technical needs (Section
\ref{sec:needs}), few emphasized the need to assess human-focused
qualities like user interface and user experience, interpretability,
meaningfulness, or trust. Most studies also identified interpretability
as an advantage of localized models, though none evaluated model
interpretability and few proposed new interpretative uses. Lack of trust
in ML tools is a long-recognized problem that direct intepretability of
model components could help alleviate, but this is more often assumed
than demonstrated. One valuable direction for future work would be to
compare the ability of non-technical investigators or users to draw
correct inferences from these and other interpretable methods and their
levels of confidence in those inferences.

We posit that an essential component of such ``soft'' performance goals
is the ability of the user community to exert some control over the
models. Given the impact on performance of the choice or optimization of
the similarity measure, an important target for user input would be the
importance of certain variables in the calculation of similarity, with
an understanding of how it can impact not only the performance of the
predictions but also the cohort retrieved for the model. For one
example, a user may want to minimize the weight of rare diseases in
medical history in order to retrieve a population with more such cases
in order to better measure their associated risk to the outcome. In
contrast, they may want to increase the weight of the indicating
diagnosis in order to allow fewer patients from similar but distinct
populations to influence the model. For another example, a user may want
to down-weight socioeconomic variables like race--ethnicity in order to
ensure a more diverse modeling cohort. Future purely quantitative work
could assess whether similarity-tuning can achieve these ends more
flexibly than strict inclusion/exclusion criteria.

\hypertarget{conclusions}{%
\subsection{Conclusions}\label{conclusions}}

We propose the term \emph{localized modeling} to encompass an approach
derived from CBR in which parameterized models are fitted in a
standardized way to nearest neighborhoods of past or training cases
according to a measure of patient similarity. We conducted a systematic
search for studies that apply localized models to tasks involving health
data and synthesized these largely independently developed approaches
into a general framework. While the search was limited by low
inter-rater reliability and failure to recover several motivating
examples, the included studies used many of the same underlying tools to
build, optimize, and evaluate their methods. We therefore believe that
our framework can serve to taxonomize ongoing work of this type and
inform the development of customizable implementations. Indeed, the
availability of increasing computational power, the diversity of tasks
to which these models were applied and of technical specifications they
employed, and the apparent lack of any multi-group research program to
date suggest great potential for growth. Whereas precious few of the
reviewed studies used these models, for any task other than prediction,
despite widespread suspicion among clinicians of ``black-box'' models
and growing interest in interpretable alternatives, we recommend that
future work put greater emphasis on the development and validation of
interpretable localized models and on their reception by communities of
medical research and clinical practice.

\hypertarget{acknowledgments}{%
\section{Acknowledgments}\label{acknowledgments}}

We are grateful for the astute and supportive comments of three
anonymous reviewers.

\hypertarget{support}{%
\section{Support}\label{support}}

The authors received no specific funding or other support for this work.

\hypertarget{competing-interests}{%
\section{Competing interests}\label{competing-interests}}

The authors declare that they have no competing interests.

\hypertarget{data-and-code}{%
\section{Data and code}\label{data-and-code}}

\label{sec:data}

Search results are publicly available in a Zotero group library. Data
collected or encoded for included studies are publicly available in two
Google Sheets. Code used to analyze these data and generate this
manuscript is publicly available in a GitHub repository.

\begin{itemize}
\tightlist
\item
  Search results, included studies, and other bibliography:
  \url{https://www.zotero.org/groups/5017571/imsr/}
\item
  Bibliographic and methodological properties of included studies:
  \url{https://docs.google.com/spreadsheets/d/1tpWMhYH2pyRT55K7n2J2XFs-kEV_JTuCDmXzJ4BBgNo/}
\item
  Terminology and composite techniques of included studies:
  \url{https://docs.google.com/spreadsheets/d/1xvDJwiLBoI2oz8fxHJ5MjNmiju_RAlK7RJv-wXe1DAs/}
\item
  Code used to conduct analyses and prepare the manuscript:
  \url{https://github.com/corybrunson/imsr}
\end{itemize}

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{research-question}{%
\subsection{Research question}\label{research-question}}

How is patient similarity--based individualized modeling conducted using
retrospective data?

\hypertarget{purpose-of-review}{%
\subsection{Purpose of review}\label{purpose-of-review}}

\label{sec:appendix-purpose}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Provide a summary of individualized models to date.
\item
  Lay the groundwork for conducting a comparison study of individualized
  models.
\item
  Provide a framework for future individualized modeling studies.
\end{enumerate}

\hypertarget{search-1}{%
\subsection{Search}\label{search-1}}

\label{sec:appendix-search}

The procedure for formulating the search began with an evaluation of the
research question. We highlighted specific elements within our topic of
interest that we found critical to our search and listed them using an
OR of ANDs, pairing terms we believed would provide our desired result.
Following the solidification of the search, a thesaurus was created in
which each term was expanded by synonyms that are similar enough to our
core term to be applicable to our search. The expanded search string was
then evaluated using the PubMed Advanced Search platform. We initially
included each term and their synonyms separately to evaluate what
resulted. Several terms were eliminated due to PubMed classifying them
as ``phrases not found'' and other terms were removed to reduce the
number of results, providing a more concise list of results. At the
conclusions of this process for each individual term, we combined each
search term using an OR of ANDs to ultimately form our search.

The search will have been designed to recover studies of the kind
reviewed by the review papers from which we obtained our ``seed set''.
To validate the final search design, we will determine how many of the
papers in this seed set that are indexed by PubMed are actually
recovered by our search. In most cases, the focus of a review paper is
different from ours, so we will only perform this validation test on the
seed set obtained from two review papers that are (a) closest in focus
to ours and (b) use terminology associated with the two distinct
sub-literatures relevant to our focus: Choudhury \& Begum (2016), which
focuses on case-based reasoning in medicine, and Sharafoddini, Dubin, \&
Lee (2017), which focuses on patient similarity--based prediction models
on health data. The proportion of each PubMed-indexed seed set that is
recovered from our PubMed search provides a rough and optimistic yet
useful estimate of the proportion of the relevant literature that our
full search strategy will recover.

Once we have finalized the search as a logical pattern, we will take the
following steps to generate the sample/corpus of literature that will be
the starting point for our selection process.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The logical pattern will be converted to a search string using the
  syntax appropriate to each database in our search strategy. These
  include PubMed (already done as part of the search design), Web of
  Science, Academic Search Premier/Elite, and Mathematical Reviews.
\item
  The search will be conducted on each database and the results
  organized into a Zotero collection, with one subcollection for each
  database.
\item
  Duplicate results will be identified and merged. (A result obtained
  from multiple databases should have only one Zotero entry but should
  be filed under the subcollection for each database in which it was
  found.)
\end{enumerate}

Following discussion among AC, PMJ, and JCB, we discarded results from
Google Scholar due to missing abstracts, missing URLs, high overlap with
other search results, and irreproducibility of the search process.

\hypertarget{search-strings}{%
\subsubsection{Search strings}\label{search-strings}}

Here we reproduce the search strings and platform specifications used in
our literature search. We first finalized the \textbf{PubMed} search
string below:\footnote{\url{https://pubmed.ncbi.nlm.nih.gov/?term=(+\%22case-based+reasoning\%22+\%5BAll+Fields\%5D+OR+\%22case-based+system\%22+\%5BAll+Fields\%5D+)+OR+(+\%22individualized+modeling\%22+\%5BAll+Fields\%5D+OR+\%22personalized+modeling\%22+\%5BAll+Fields\%5D+OR+\%22customized+modeling\%22+\%5BAll+Fields\%5D+)+OR+(+\%22individualized+cohort\%22+\%5BAll+Fields\%5D+)+OR+(+(+\%22patient+similarity\%22+\%5BAll+Fields\%5D+OR+\%22patient+distance\%22+\%5BAll+Fields\%5D+OR+\%22patient+connection\%22+\%5BAll+Fields\%5D+OR+\%22patient+affinity\%22+\%5BAll+Fields\%5D+OR+\%22patient+clustering\%22+\%5BAll+Fields\%5D+)+AND+(+\%22cohort+study\%22+\%5BAll+Fields\%5D+)+)\&sort=date}}

\begin{verbatim}
(
  "case-based reasoning" [All Fields] OR
  "case-based system" [All Fields]
) OR (
  "individualized modeling" [All Fields] OR
  "personalized modeling" [All Fields] OR
  "customized modeling" [All Fields]
) OR (
  "individualized cohort" [All Fields]
) OR (
  (
    "patient similarity" [All Fields] OR
    "patient distance" [All Fields] OR
    "patient connection" [All Fields] OR
    "patient affinity" [All Fields] OR
    "patient clustering" [All Fields]
  ) AND (
    "cohort study" [All Fields]
  )
)
\end{verbatim}

This search yielded 423 results.

We then generated analogous search strings or search strategies for the
Web of Science, Academic Search Premier, and MathSciNet platforms, based
on the logics and syntaxes of their respective interfaces.

For \textbf{Web of Science}, we searched for several separate
disjunctions derived from the PubMed search string. The separate search
strings and the number of results obtained using each are below.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4444}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2361}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Search string
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Number of items
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{"case-based\ reasoning"\ OR} \texttt{"case-based\ system"} &
3,636 \\
\texttt{"individualized\ model"\ OR}
\texttt{"individualized\ modeling"\ OR}
\texttt{"personalized\ model"\ OR} \texttt{"personalized\ modeling"\ OR}
\texttt{"customized\ model"} \texttt{"customized\ modeling"} & 444 \\
\texttt{"individualized\ cohort"} & 1 \\
\texttt{"patient\ similarity"\ OR} \texttt{"patient\ distance"\ OR}
\texttt{"patient\ connection"\ OR} \texttt{"patient\ affinity"\ OR}
\texttt{"patient\ clustering"}; Refined search: \texttt{"cohort"} &
48 \\
\end{longtable}

We found the results of the first search string to be predominantly
irrelevant. To reduce review time, these were dropped. The last search
was refined with an additional term following the initial disjunctive
search. Our searches on Web of Science thus yielded 493 results.

When searching \textbf{Academic Search Premier}, we checked the option
``Scholarly (Peer-Reviewed) Journals'', unchecked the option ``Apply
equivalent subjects'', and searched for several separate disjunctions
and conjunctions of strings in the ``TX All Text'' field. We obtained
the resulting citations via email in RIS format.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4444}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2361}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Search string
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Number of items
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{"case-based\ reasoning"\ OR} \texttt{"case-based\ system"} &
3,283 \\
\texttt{"individualized\ modeling"\ OR}
\texttt{"personalized\ modeling"\ OR} \texttt{"customized\ modeling"} &
100 \\
\texttt{"individualized\ cohort"} & 2 \\
\texttt{"patient\ similarity"\ AND} \texttt{"cohort\ study"} & 14 \\
\texttt{"patient\ distance"\ AND} \texttt{"cohort\ study"} & 15 \\
\texttt{"patient\ connection"\ AND} \texttt{"cohort\ study"} & 6 \\
\texttt{"patient\ affinity"\ AND} \texttt{"cohort\ study"} & 0 \\
\texttt{"patient\ clustering"\ AND} \texttt{"cohort\ study"} & 50 \\
\end{longtable}

We found the results of the first search string to be predominantly
irrelevant. To reduce review time, these were dropped. Our searches on
Academic Search Premier thus yielded 187 results.

For \textbf{MathSciNet}, the portal to the \emph{Mathematical Reviews}
database, we used the same separate searches as for Web of Science, in
some cases expanded to obtain more results. Those which yielded nonzero
numbers of results are below:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.4444}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2361}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Search string
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
Number of items
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{"case-based\ reasoning"} & 110 \\
\texttt{"individualized\ model} & 2 \\
\texttt{"patient\ similarity"\ AND} \texttt{"cohort"} & 1 \\
\end{longtable}

Our searches of \emph{Mathematical Reviews} therefore yielded 113
results.

These totaled 1,422 sources from all platforms. We organized the full
results in a public Zotero collection alongside the seed set and created
a single folder for the 25 results reviewed in detail.

\hypertarget{screening-process}{%
\subsection{Screening process}\label{screening-process}}

\label{sec:appendix-screening}

Most deduplication was done automatically in Covidence. As full-text
review was done in Zotero, some additional duplicates were noticed and
merged.

When abstracts were not obtained by search or by Covidence, we attempted
to find them online using DOIs; when an abstract could not be found,
screening was based on the title alone. We decided to screen titles and
abstracts conservatively, rejecting only studies that were clearly
outside the scope of our review. The reasons for rejection were four, as
discussed in the main text: a. Exclude non clinical/non medical setting
b. Must be in English c.~Must be original study (not reviews, surveys,
opinion, news) d.~Exclude if search term clearly has different meaning
than intended (Two examples of (d) are the use of the term
``personalized model'' to refer in some cases to parameterized models
tuned to individual patient measurements and in others to
patient-centered models of care.) Studies that passed title/abstract
screen were exported to Zotero.

\hypertarget{selection-process}{%
\subsection{Selection process}\label{selection-process}}

\label{sec:appendix-selection}

Some PDFs were obtained using Zotero from a university workstation, and
the remaining were obtained through university library services. The
review process is detailed in Section \ref{sec:full-text}.

Our selection of relevant papers from the search corpus was based on the
following inclusion/exclusion criteria:

\begin{itemize}
\tightlist
\item
  Uses labeled case-level (empirical) data set
\item
  Defines a continuous-valued multivariate case similarity measure
\item
  Uses the similarity measure to select cohorts for index cases from the
  corpus
\item
  Fits statistical models to cohorts to make inferences about index
  cases
\end{itemize}

We decided after concluding full-text review to perform one round of
citation-tracking, of citations within the Methods (or analogous)
sections of the included entries.

\hypertarget{analysis-and-synthesis}{%
\subsection{Analysis and synthesis}\label{analysis-and-synthesis}}

Because we could not predict the scope of methodological approaches we
would encounter, we did not prepare specific analyses or syntheses
\emph{a priori}.

\hypertarget{performance-evaluations-and-comparisons}{%
\subsection{Performance evaluations and
comparisons}\label{performance-evaluations-and-comparisons}}

\begin{landscape}

\textbf{TODO: Place vertical separators between major columns.}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1224}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.0714}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.1633}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.2398}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.0969}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.2092}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 12\tabcolsep) * \real{0.0969}}@{}}
\caption{\label{tab:performance}Evaluations of proposed methods and
comparisons to alternative methods. (See original studies for full names
and descriptions.)}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Citation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Proposals
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Comparators
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Citation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Proposals
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Comparators
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}20{]} & Accuracy & Arthritis & Kohonen + CBR & 75.60\%\hspace{6em} &
Kohonen mapping & 54.70\%\hspace{6em} \\
& & & & \hspace{6em} & CBR & 60.40\%\hspace{6em} \\
& & & & \hspace{6em} & Quest & 50.90\%\hspace{6em} \\
& & & & \hspace{6em} & backpropagation & 54.70\%\hspace{6em} \\
{[}13{]} & Accuracy & Dermatology & Statistical CBR &
96.57\%\hspace{6em} & CBR & 95.43\%\hspace{6em} \\
& & & & \hspace{6em} & C5.0 & 93.71\%\hspace{6em} \\
& & & & \hspace{6em} & CART & 92.00\%\hspace{6em} \\
& & & & \hspace{6em} & LR & 91.14\%\hspace{6em} \\
& & & & \hspace{6em} & NN & 88.29\%\hspace{6em} \\
& & Heart & Statistical CBR & 83.70\%\hspace{6em} & LR &
84.44\%\hspace{6em} \\
& & & & \hspace{6em} & NN & 82.22\%\hspace{6em} \\
& & & & \hspace{6em} & CBR & 81.85\%\hspace{6em} \\
& & & & \hspace{6em} & CART & 76.67\%\hspace{6em} \\
& & & & \hspace{6em} & C5.0 & 76.30\%\hspace{6em} \\
& & Breast & Statistical CBR & 96.96\%\hspace{6em} & NN &
97.50\%\hspace{6em} \\
& & & & \hspace{6em} & CBR & 96.61\%\hspace{6em} \\
& & & & \hspace{6em} & LR & 96.61\%\hspace{6em} \\
& & & & \hspace{6em} & C5.0 & 94.29\%\hspace{6em} \\
& & & & \hspace{6em} & CART & 92.14\%\hspace{6em} \\
& & Diabetes & Statistical CBR & 76.32\%\hspace{6em} & LR &
77.11\%\hspace{6em} \\
& & & & \hspace{6em} & CBR & 73.16\%\hspace{6em} \\
& & & & \hspace{6em} & C5.0 & 73.15\%\hspace{6em} \\
& & & & \hspace{6em} & CART & 72.89\%\hspace{6em} \\
& & & & \hspace{6em} & NN & 65.39\%\hspace{6em} \\
& & Liver & Statistical CBR & 66.76\%\hspace{6em} & CART &
67.94\%\hspace{6em} \\
& & & & \hspace{6em} & LR & 67.35\%\hspace{6em} \\
& & & & \hspace{6em} & C5.0 & 66.47\%\hspace{6em} \\
& & & & \hspace{6em} & CBR & 60.88\%\hspace{6em} \\
& & & & \hspace{6em} & NN & 55.59\%\hspace{6em} \\
{[}21{]} & RMSE & GFR & TWNFI & 7.08\hspace{6em} & MDRD &
7.74\hspace{6em} \\
& & & & \hspace{6em} & MLP & 8.38\hspace{6em} \\
& & & & \hspace{6em} & ANFIS & 7.40\hspace{6em} \\
& & & & \hspace{6em} & DENFIS & 7.22\hspace{6em} \\
& & & & \hspace{6em} & TNFI & 7.28\hspace{6em} \\
{[}22{]} & AUROC & mammography mass region & CBR & 0.885\hspace{6em} &
DT & 0.872\hspace{6em} \\
& & & & \hspace{6em} & ANN & 0.882\hspace{6em} \\
{[}23{]} & Accuracy & Return-to-work & CBR & 62.5\%\hspace{6em} & LR &
71.2\%\hspace{6em} \\
{[}18{]} & Accuracy & Colon cancer diagnosis & TWNFI &
91.9\%\hspace{6em} & MLR (Personalized) & 82.3\%\hspace{6em} \\
& & & & \hspace{6em} & SVM (Personalized) & 90.3\%\hspace{6em} \\
& & & & \hspace{6em} & WKNN & 90.3\%\hspace{6em} \\
& & Crohn's disease risk & TWNFI & 82.45\%\hspace{6em} & &
\hspace{6em} \\
{[}26{]} & Accuracy & Colon cancer & knnGSA & 85.48\%\hspace{6em} & SVM
& 82.14\%\hspace{6em} \\
& & & svmGSA & 87.10\%\hspace{6em} & ECF & 72.30\%\hspace{6em} \\
& & & & \hspace{6em} & KNN & 82.14\%\hspace{6em} \\
& & & & \hspace{6em} & WKNN & 82.14\%\hspace{6em} \\
& & Leukemia & knnGSA & 97.22\%\hspace{6em} & SVM &
95.83\%\hspace{6em} \\
& & & svmGSA & 97.22\%\hspace{6em} & ECF & 94.44\%\hspace{6em} \\
& & & & \hspace{6em} & KNN & 94.44\%\hspace{6em} \\
& & & & \hspace{6em} & WKNN & 94.44\%\hspace{6em} \\
& & Lymphoma & knnGSA & 94.81\%\hspace{6em} & SVM &
93.51\%\hspace{6em} \\
& & & svmGSA & 94.81\%\hspace{6em} & ECF & 92.21\%\hspace{6em} \\
& & & & \hspace{6em} & KNN & 93.51\%\hspace{6em} \\
& & & & \hspace{6em} & WKNN & 93.51\%\hspace{6em} \\
& & Lung cancer & knnGSA & 98.34\%\hspace{6em} & SVM &
95.31\%\hspace{6em} \\
& & & svmGSA & 98.90\%\hspace{6em} & ECF & 92.87\%\hspace{6em} \\
& & & & \hspace{6em} & KNN & 96.60\%\hspace{6em} \\
& & & & \hspace{6em} & WKNN & 95.50\%\hspace{6em} \\
{[}12{]} & Relative IPEC & Graft survival & MKNN & 0.973\hspace{6em} &
RSF & 0.957\hspace{6em} \\
{[}27{]} & AUROC & Waitlist registration, complete & CBR + Wj &
89.8\%\hspace{6em} & LR & 92.0\%\hspace{6em} \\
& & & CBR + Wk & 90.7\%\hspace{6em} & Standalone CBR &
90.4\%\hspace{6em} \\
& & & CBR + Wj + Wk & 87.4\%\hspace{6em} & & \hspace{6em} \\
& & Waitlist registration, stepwise & CBR + Wj & 82.7\%\hspace{6em} & LR
& 92.1\%\hspace{6em} \\
& & & CBR + Wk & 86.2\%\hspace{6em} & Standalone CBR &
91.4\%\hspace{6em} \\
& & & CBR + Wj + Wk & 88.5\%\hspace{6em} & & \hspace{6em} \\
{[}28{]} & Accuracy & Nevus & Collaborative + rules & 98\%\hspace{6em} &
Dermoscopy CBR & 92\%\hspace{6em} \\
& & & Collaborative + rules + DML & 100\%\hspace{6em} & Confocal CBR &
96\%\hspace{6em} \\
& & & & \hspace{6em} & Collaborative & 95\%\hspace{6em} \\
{[}15{]} & AUROC & Diabetes onset & Personalized LR
(LSML+FeatureFiltering) & 0.624\hspace{6em} & KNN & 0.617\hspace{6em} \\
& & & Personalized LR (LSML) & 0.619\hspace{6em} & Global LR &
0.611\hspace{6em} \\
& & & Personalized LR (Euclidean) & 0.614\hspace{6em} & &
\hspace{6em} \\
& & & Personalized LR (Random) & 0.602\hspace{6em} & & \hspace{6em} \\
{[}14{]} & AUROC & 30-day mortality & Individualized LR &
0.830\hspace{6em} & Individualized DC & 0.797\hspace{6em} \\
& & & Individualized DT & 0.753\hspace{6em} & & \hspace{6em} \\
{[}16{]} & AUROC & & Individualized LR & 0.824\hspace{6em} &
Individualized DC & 0.801\hspace{6em} \\
& & & Individualized DT & 0.779\hspace{6em} & & \hspace{6em} \\
& & & Individualized RF & 0.839\hspace{6em} & & \hspace{6em} \\
& & & Individualized CSRF & 0.832\hspace{6em} & & \hspace{6em} \\
{[}31{]} & Accuracy & J13/pneumonia & Case-based NN & 81.6\%\hspace{6em}
& & \hspace{6em} \\
& & K80.1/gallbladder & Case-based NN & 76.7\%\hspace{6em} & &
\hspace{6em} \\
& & H25.1/age-related cataract & Case-based NN & 94.9\%\hspace{6em} & &
\hspace{6em} \\
& & H26.2/complicated cataract & Case-based NN & 91.4\%\hspace{6em} & &
\hspace{6em} \\
& & 167.4/encephalopathy & Case-based NN & 72.4\%\hspace{6em} & &
\hspace{6em} \\
& & 167.9/CBD & Case-based NN & 75.4\%\hspace{6em} & & \hspace{6em} \\
& & N20.1/ureter & Case-based NN & 58.7\%\hspace{6em} & &
\hspace{6em} \\
{[}30{]} & AUROC & Cognitive impairment & Gaussian process regression
with custom kernel & 0.92\hspace{6em} & linear regression without
regularization & 0.81\hspace{6em} \\
& & & & \hspace{6em} & LASSO regression & 0.85\hspace{6em} \\
& & & & \hspace{6em} & ridge regression & 0.87\hspace{6em} \\
& & & & \hspace{6em} & RF & 0.90\hspace{6em} \\
& & & & \hspace{6em} & gradient boosting regression tree &
0.91\hspace{6em} \\
& & & & \hspace{6em} & XGBoost & 0.91\hspace{6em} \\
& & & & \hspace{6em} & kernel support vector regressor &
0.92\hspace{6em} \\
& & Parkinson's disease & Gaussian process regression with custom kernel
& 0.875\hspace{6em} & linear regression without regularization &
0.820\hspace{6em} \\
& & & & \hspace{6em} & ridge regression & 0.798\hspace{6em} \\
& & & & \hspace{6em} & RF & 0.734\hspace{6em} \\
& & & & \hspace{6em} & gradient boosting regression tree &
0.825\hspace{6em} \\
& & & & \hspace{6em} & kernel support vector regressor &
0.778\hspace{6em} \\
{[}17{]} & AUROC & Diabetes & Personalized RF & 0.90\hspace{6em} & &
\hspace{6em} \\
& & & Personalized KNN & 0.82\hspace{6em} & & \hspace{6em} \\
& & & Personalized LR & 0.89\hspace{6em} & & \hspace{6em} \\
{[}32{]} & AUROC & Discharge at 10 days & One-class JITL-ELM &
0.8510\hspace{6em} & ELM & 0.4973\hspace{6em} \\
& & & & \hspace{6em} & JITL-ELM & 0.2014\hspace{6em} \\
& & & & \hspace{6em} & One-class ELM & 0.7588\hspace{6em} \\
& & & & \hspace{6em} & One-class SVM & 0.4647\hspace{6em} \\
\end{longtable}

\end{landscape}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\leavevmode\vadjust pre{\hypertarget{ref-Longhurst2014}{}}%
\CSLLeftMargin{{[}1{]} }%
\CSLRightInline{Longhurst CA, Harrington RA, Shah NH. A {``{Green
Button}''} {For Using Aggregate Patient Data At The Point Of Care}.
Health Affairs 2014;33:1229--35.
\url{https://doi.org/10.1377/hlthaff.2014.0099}.}

\leavevmode\vadjust pre{\hypertarget{ref-Aamodt1994}{}}%
\CSLLeftMargin{{[}2{]} }%
\CSLRightInline{Aamodt A, Plaza E. Case-{Based Reasoning}: {Foundational
Issues}, {Methodological Variations}, and {System Approaches}. AI
Communications 1994;7:39--59.
\url{https://doi.org/10.3233/AIC-1994-7104}.}

\leavevmode\vadjust pre{\hypertarget{ref-Begum2011}{}}%
\CSLLeftMargin{{[}3{]} }%
\CSLRightInline{Begum S, Ahmed MU, Funk P, Xiong N, Folke M. Case-{Based
Reasoning Systems} in the {Health Sciences}: {A Survey} of {Recent
Trends} and {Developments}. IEEE Transactions on Systems, Man, and
Cybernetics, Part C (Applications and Reviews) 2011;41:421--34.
\url{https://doi.org/10.1109/TSMCC.2010.2071862}.}

\leavevmode\vadjust pre{\hypertarget{ref-Kolodner1992}{}}%
\CSLLeftMargin{{[}4{]} }%
\CSLRightInline{Kolodner JL. An introduction to case-based reasoning.
Artificial Intelligence Review 1992;6:3--34.
\url{https://doi.org/10.1007/BF00155578}.}

\leavevmode\vadjust pre{\hypertarget{ref-Gierl1998}{}}%
\CSLLeftMargin{{[}5{]} }%
\CSLRightInline{Gierl L, Bull M, Schmidt R. {CBR} in {Medicine}. In:
Lenz M, Burkhard H-D, Bartsch-Spörl B, Wess S, editors. Case-{Based
Reasoning Technology}, vol. 1400, {Berlin, Heidelberg}: {Springer Berlin
Heidelberg}; 1998, p. 273--97.
\url{https://doi.org/10.1007/3-540-69351-3_11}.}

\leavevmode\vadjust pre{\hypertarget{ref-Choudhury2016}{}}%
\CSLLeftMargin{{[}6{]} }%
\CSLRightInline{Choudhury N, Begum SA. A {Survey} on {Case-based
Reasoning} in {Medicine}. International Journal of Advanced Computer
Science and Applications 2016;7.
\url{https://doi.org/10.14569/IJACSA.2016.070820}.}

\leavevmode\vadjust pre{\hypertarget{ref-Dai2020}{}}%
\CSLLeftMargin{{[}7{]} }%
\CSLRightInline{Dai L, Zhu H, Liu D.
\href{https://arxiv.org/abs/2012.01976}{Patient similarity: Methods and
applications}. arXiv:201201976 {[}Cs{]} 2020.}

\leavevmode\vadjust pre{\hypertarget{ref-Welch2013}{}}%
\CSLLeftMargin{{[}8{]} }%
\CSLRightInline{Welch BM, Kawamoto K. Clinical decision support for
genetically guided personalized medicine: A systematic review. Journal
of the American Medical Informatics Association 2013;20:388--400.
\url{https://doi.org/10.1136/amiajnl-2012-000892}.}

\leavevmode\vadjust pre{\hypertarget{ref-Sharafoddini2017}{}}%
\CSLLeftMargin{{[}9{]} }%
\CSLRightInline{Sharafoddini A, Dubin JA, Lee J. Patient {Similarity} in
{Prediction Models Based} on {Health Data}: {A Scoping Review}. JMIR
Medical Informatics 2017;5:e7.
\url{https://doi.org/10.2196/medinform.6730}.}

\leavevmode\vadjust pre{\hypertarget{ref-Parimbelli2018}{}}%
\CSLLeftMargin{{[}10{]} }%
\CSLRightInline{Parimbelli E, Marini S, Sacchi L, Bellazzi R. Patient
similarity for precision medicine: {A} systematic review. Journal of
Biomedical Informatics 2018;83:87--96.
\url{https://doi.org/10.1016/j.jbi.2018.06.001}.}

\leavevmode\vadjust pre{\hypertarget{ref-Mariuzzi1997}{}}%
\CSLLeftMargin{{[}11{]} }%
\CSLRightInline{Mariuzzi G, Mombello A, Mariuzzi L, Hamilton PW, Weber
JE, Thompson D, et al. Quantitative study of ductal breast
cancer--patient targeted prognosis: An exploration of case base
reasoning. Pathology - Research and Practice 1997;193:535--42.
\url{https://doi.org/10.1016/S0344-0338(97)80011-8}.}

\leavevmode\vadjust pre{\hypertarget{ref-Lowsky2013}{}}%
\CSLLeftMargin{{[}12{]} }%
\CSLRightInline{Lowsky DJ, Ding Y, Lee DKK, McCulloch CE, Ross LF,
Thistlethwaite JR, et al. A {K-nearest} neighbors survival probability
prediction method. Statistics in Medicine 2013;32:2062--9.
\url{https://doi.org/10.1002/sim.5673}.}

\leavevmode\vadjust pre{\hypertarget{ref-Park2006}{}}%
\CSLLeftMargin{{[}13{]} }%
\CSLRightInline{Park Y-J, Kim B-C, Chun S-H. New knowledge extraction
technique using probability for case-based reasoning: Application to
medical diagnosis. Expert Systems 2006;23:2--20.
\url{https://doi.org/10.1111/j.1468-0394.2006.00321.x}.}

\leavevmode\vadjust pre{\hypertarget{ref-Lee2015}{}}%
\CSLLeftMargin{{[}14{]} }%
\CSLRightInline{Lee J, Maslove DM, Dubin JA. Personalized {Mortality
Prediction Driven} by {Electronic Medical Data} and a {Patient
Similarity Metric}. PLOS ONE 2015;10:e0127428.
\url{https://doi.org/10.1371/journal.pone.0127428}.}

\leavevmode\vadjust pre{\hypertarget{ref-Ng2015}{}}%
\CSLLeftMargin{{[}15{]} }%
\CSLRightInline{Ng K, Sun J, Hu J, Wang F.
\href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4525240}{Personalized
{Predictive Modeling} and {Risk Factor Identification} using {Patient
Similarity}}. AMIA Joint Summits on Translational Science Proceedings
AMIA Joint Summits on Translational Science 2015;2015:132--6.}

\leavevmode\vadjust pre{\hypertarget{ref-Lee2017}{}}%
\CSLLeftMargin{{[}16{]} }%
\CSLRightInline{Lee J. Patient-{Specific Predictive Modeling Using
Random Forests}: {An Observational Study} for the {Critically Ill}. JMIR
Medical Informatics 2017;5:e3.
\url{https://doi.org/10.2196/medinform.6690}.}

\leavevmode\vadjust pre{\hypertarget{ref-Wang2019}{}}%
\CSLLeftMargin{{[}17{]} }%
\CSLRightInline{Wang N, Huang Y, Liu H, Fei X, Wei L, Zhao X, et al.
Measurement and application of patient similarity in personalized
predictive modeling based on electronic medical records. BioMedical
Engineering OnLine 2019;18.
\url{https://doi.org/10.1186/s12938-019-0718-2}.}

\leavevmode\vadjust pre{\hypertarget{ref-Kasabov2010}{}}%
\CSLLeftMargin{{[}18{]} }%
\CSLRightInline{Kasabov N, Hu Y. Integrated optimisation method for
personalised modelling and case studies for medical decision support.
International Journal of Functional Informatics and Personalised
Medicine 2010;3:236--56.
\url{https://doi.org/10.1504/IJFIPM.2010.039123}.}

\leavevmode\vadjust pre{\hypertarget{ref-Yearwood1997a}{}}%
\CSLLeftMargin{{[}19{]} }%
\CSLRightInline{Yearwood J, Wilkinson R. Retrieving cases for treatment
advice in nursing using text representation and structured text
retrieval. Artificial Intelligence in Medicine 1997;9:79--99.
\url{https://doi.org/10.1016/s0933-3657(96)00362-4}.}

\leavevmode\vadjust pre{\hypertarget{ref-Wyns2004a}{}}%
\CSLLeftMargin{{[}20{]} }%
\CSLRightInline{Wyns B, Sette S, Boullart L, Baeten D, Hoffman IEA, De
Keyser F. Prediction of diagnosis in patients with early arthritis using
a combined {Kohonen} mapping and instance-based evaluation criterion.
Artificial Intelligence in Medicine 2004;31:45--55.
\url{https://doi.org/10.1016/j.artmed.2004.01.002}.}

\leavevmode\vadjust pre{\hypertarget{ref-Song2006c}{}}%
\CSLLeftMargin{{[}21{]} }%
\CSLRightInline{Song Q, Kasabov N. {TWNFI} \textemdash{} a transductive
neuro-fuzzy inference system with weighted data normalization for
personalized modeling. Neural Networks 2006;19:1591--6.}

\leavevmode\vadjust pre{\hypertarget{ref-Elter2007a}{}}%
\CSLLeftMargin{{[}22{]} }%
\CSLRightInline{Elter M, Schulz-Wendtland R, Wittenberg T. The
prediction of breast cancer biopsy outcomes using two {CAD} approaches
that both emphasize an intelligible decision process. Medical Physics
2007;34:4164--72. \url{https://doi.org/10.1118/1.2786864}.}

\leavevmode\vadjust pre{\hypertarget{ref-Xu2008a}{}}%
\CSLLeftMargin{{[}23{]} }%
\CSLRightInline{Xu Y, Chan CCH, Lo KHY-L, Tang D. Prediction model for
the return to work of workers with injuries in {Hong Kong}. Work
2008;30:77--84.}

\leavevmode\vadjust pre{\hypertarget{ref-Lopez2011a}{}}%
\CSLLeftMargin{{[}24{]} }%
\CSLRightInline{López B, Pous C, Gay P, Pla A, Sanz J, Brunet J.
{eXiT}*{CBR}: {A} framework for case-based medical diagnosis development
and experimentation. Artificial Intelligence in Medicine 2011;51:81--91.
\url{https://doi.org/10.1016/j.artmed.2010.09.002}.}

\leavevmode\vadjust pre{\hypertarget{ref-Verma2015a}{}}%
\CSLLeftMargin{{[}25{]} }%
\CSLRightInline{Verma A, Fiasche M, Cuzzola M, Irrera G. Comparative
study of existing personalized approaches for identifying important gene
markers and for risk estimation in {Type2 Diabetes} in {Italian}
population. Evolving Systems 2015;6:15--22.
\url{https://doi.org/10.1007/s12530-013-9083-8}.}

\leavevmode\vadjust pre{\hypertarget{ref-Liang2015a}{}}%
\CSLLeftMargin{{[}26{]} }%
\CSLRightInline{Liang W, Hu Y, Kasabov N. Evolving personalized modeling
system for integrated feature, neighborhood and parameter optimization
utilizing gravitational search algorithm. Evolving Systems 2015;6:1--14.
\url{https://doi.org/10.1007/s12530-013-9081-x}.}

\leavevmode\vadjust pre{\hypertarget{ref-CampilloGimenez2012a}{}}%
\CSLLeftMargin{{[}27{]} }%
\CSLRightInline{Campillo-Gimenez B, Bayat S, Cuggia M. Coupling
{K-nearest} neighbors with logistic regression in case-based reasoning.
Studies in Health Technology and Informatics 2012;180:275--9.}

\leavevmode\vadjust pre{\hypertarget{ref-Nicolas2014a}{}}%
\CSLLeftMargin{{[}28{]} }%
\CSLRightInline{Nicolas R, Fornells A, Golobardes E, Corral G, Puig S,
Malvehy J. {DERMA}: A melanoma diagnosis platform based on collaborative
multilabel analog reasoning. The Scientific World Journal
2014;2014:351518. \url{https://doi.org/10.1155/2014/351518}.}

\leavevmode\vadjust pre{\hypertarget{ref-Vilhena2016a}{}}%
\CSLLeftMargin{{[}29{]} }%
\CSLRightInline{Vilhena J, Vicente H, Martins MR, Grañeda JM, Caldeira
F, Gusmão R, et al. A case-based reasoning view of thrombophilia risk.
Journal of Biomedical Informatics 2016;62:265--75.
\url{https://doi.org/10.1016/j.jbi.2016.07.013}.}

\leavevmode\vadjust pre{\hypertarget{ref-Zhang2018a}{}}%
\CSLLeftMargin{{[}30{]} }%
\CSLRightInline{Zhang H, Zhu F, Dodge H, Higgins G, Omenn G, Guan Y, et
al. A similarity-based approach to leverage multi-cohort medical data on
the diagnosis and prognosis of {Alzheimer}'s disease. GigaScience
2018;7. \url{https://doi.org/10.1093/gigascience/giy085}.}

\leavevmode\vadjust pre{\hypertarget{ref-Malykh2018a}{}}%
\CSLLeftMargin{{[}31{]} }%
\CSLRightInline{Malykh VL, Rudetskiy SV. Approaches to {Medical
Decision-Making Based} on {Big Clinical Data}. Journal of Healthcare
Engineering 2018;2018:3917659.
\url{https://doi.org/10.1155/2018/3917659}.}

\leavevmode\vadjust pre{\hypertarget{ref-Ma2020a}{}}%
\CSLLeftMargin{{[}32{]} }%
\CSLRightInline{Ma X, Si Y, Wang Z, Wang Y. Length of stay prediction
for {ICU} patients using individualized single classification algorithm.
Computer Methods and Programs in Biomedicine 2020;186.
\url{https://doi.org/10.1016/j.cmpb.2019.105224}.}

\leavevmode\vadjust pre{\hypertarget{ref-Wang2020}{}}%
\CSLLeftMargin{{[}33{]} }%
\CSLRightInline{Wang Y, Liang Y, Sun H, Yang Y. Emergency {Response} for
{COVID-19 Prevention} and {Control} in {Urban Rail Transit Based} on
{Case-Based Reasoning Method}. Discrete Dynamics in Nature \& Society
2020:1--9.}

\leavevmode\vadjust pre{\hypertarget{ref-Tang2021c}{}}%
\CSLLeftMargin{{[}34{]} }%
\CSLRightInline{Tang P, Miller S, Stavropoulos H, Kartoun U, Zambrano J,
Ng K. Precision population analytics: Population management at the
point-of-care. Journal of the American Medical Informatics Association
2021;28:588--95. \url{https://doi.org/10.1093/jamia/ocaa247}.}

\leavevmode\vadjust pre{\hypertarget{ref-Ng2021b}{}}%
\CSLLeftMargin{{[}35{]} }%
\CSLRightInline{Ng K, Kartoun U, Stavropoulos H, Zambrano J, Tang P.
Personalized treatment options for chronic diseases using precision
cohort analytics. Scientific Reports 2021;11.
\url{https://doi.org/10.1038/s41598-021-80967-5}.}

\leavevmode\vadjust pre{\hypertarget{ref-Doyle2006a}{}}%
\CSLLeftMargin{{[}36{]} }%
\CSLRightInline{Doyle D, Cunningham P, Walsh P. An evaluation of the
usefulness of explanation in a case-based reasoning system for decision
support in bronchiolitis treatment. Computational Intelligence
2006;22:269--81.
\url{https://doi.org/10.1111/j.1467-8640.2006.00288.x}.}

\leavevmode\vadjust pre{\hypertarget{ref-Fang2021a}{}}%
\CSLLeftMargin{{[}37{]} }%
\CSLRightInline{Fang HSA, Tan NC, Tan WY, Oei RW, Lee ML, Hsu W. Patient
similarity analytics for explainable clinical risk prediction. BMC
Medical Informatics \& Decision Making 2021;21:1--12.}

\leavevmode\vadjust pre{\hypertarget{ref-CampilloGimenez2013}{}}%
\CSLLeftMargin{{[}38{]} }%
\CSLRightInline{Campillo-Gimenez B, Jouini W, Bayat S, Cuggia M.
Improving {Case-Based Reasoning Systems} by {Combining K-Nearest
Neighbour Algorithm} with {Logistic Regression} in the {Prediction} of
{Patients}' {Registration} on the {Renal Transplant Waiting List}. PLOS
ONE 2013;8:e71991. \url{https://doi.org/10.1371/journal.pone.0071991}.}

\leavevmode\vadjust pre{\hypertarget{ref-Matarese2022}{}}%
\CSLLeftMargin{{[}39{]} }%
\CSLRightInline{Matarese V. Kinds of {Replicability}: {Different Terms}
and {Different Functions}. Axiomathes 2022;32:647--70.
\url{https://doi.org/10.1007/s10516-021-09610-2}.}

\leavevmode\vadjust pre{\hypertarget{ref-Biecek2021}{}}%
\CSLLeftMargin{{[}40{]} }%
\CSLRightInline{Biecek P, Burzykowski T. Explanatory {Model Analysis}:
{Explore}, {Explain}, and {Examine Predictive Models}. {New York}:
{Chapman and Hall/CRC}; 2021.}

\leavevmode\vadjust pre{\hypertarget{ref-Molnar2023}{}}%
\CSLLeftMargin{{[}41{]} }%
\CSLRightInline{Molnar C. Interpretable {Machine Learning}: {A Guide}
for {Making Black Box Models Explainable}. 2023.}

\leavevmode\vadjust pre{\hypertarget{ref-Moshawrab2023}{}}%
\CSLLeftMargin{{[}42{]} }%
\CSLRightInline{Moshawrab M, Adda M, Bouzouane A, Ibrahim H, Raad A.
Reviewing {Federated Machine Learning} and {Its Use} in {Diseases
Prediction}. Sensors 2023;23:2112.
\url{https://doi.org/10.3390/s23042112}.}

\leavevmode\vadjust pre{\hypertarget{ref-Brauneck2023}{}}%
\CSLLeftMargin{{[}43{]} }%
\CSLRightInline{Brauneck A, Schmalhorst L, Majdabadi MMK, Bakhtiari M,
Völker U, Baumbach J, et al. Federated {Machine Learning},
{Privacy-Enhancing Technologies}, and {Data Protection Laws} in {Medical
Research}: {Scoping Review}. Journal of Medical Internet Research
2023;25:e41588. \url{https://doi.org/10.2196/41588}.}

\leavevmode\vadjust pre{\hypertarget{ref-Yang2006}{}}%
\CSLLeftMargin{{[}44{]} }%
\CSLRightInline{Yang L. Distance {Metric Learning}: {A Comprehensive
Survey}. PhD thesis. Michigan State University, 2006.}

\leavevmode\vadjust pre{\hypertarget{ref-Bellet2014}{}}%
\CSLLeftMargin{{[}45{]} }%
\CSLRightInline{Bellet A, Habrard A, Sebban M. A {Survey} on {Metric
Learning} for {Feature Vectors} and {Structured Data} 2014.
\url{https://doi.org/10.48550/arXiv.1306.6709}.}

\leavevmode\vadjust pre{\hypertarget{ref-Xing2002}{}}%
\CSLLeftMargin{{[}46{]} }%
\CSLRightInline{Xing E, Jordan M, Russell SJ, Ng A. Distance {Metric
Learning} with {Application} to {Clustering} with {Side-Information}.
Advances in {Neural Information Processing Systems}, vol. 15, {MIT
Press}; 2002.}

\leavevmode\vadjust pre{\hypertarget{ref-Goyal2008}{}}%
\CSLLeftMargin{{[}47{]} }%
\CSLRightInline{Goyal N, Lifshits Y, Schütze H. Disorder inequality: A
combinatorial approach to nearest neighbor search. Proceedings of the
2008 {International Conference} on {Web Search} and {Data Mining}, {New
York, NY, USA}: {Association for Computing Machinery}; 2008, p. 25--32.
\url{https://doi.org/10.1145/1341531.1341538}.}

\end{CSLReferences}


\end{document}
