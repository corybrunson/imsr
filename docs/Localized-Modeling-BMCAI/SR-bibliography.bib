@article{Aamodt1994,
  title = {Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches},
  shorttitle = {Case-Based Reasoning},
  author = {Aamodt, Agnar and Plaza, Enric},
  year = {1994},
  journal = {AI Communications},
  volume = {7},
  number = {1},
  pages = {39--59},
  issn = {09217126},
  doi = {10.3233/AIC-1994-7104},
  urldate = {2021-03-15},
  file = {/Users/jason.brunson/Zotero/storage/8MC2ZNGB/Aamodt and Plaza - 1994 - Case-Based Reasoning Foundational Issues, Methodo.pdf}
}

@article{Barbieri2022,
  title = {Predicting Cardiovascular Risk from National Administrative Databases Using a Combined Survival Analysis and Deep Learning Approach},
  author = {Barbieri, Sebastiano and Mehta, Suneela and Wu, Billy and Bharat, Chrianna and Poppe, Katrina and Jorm, Louisa and Jackson, Rod},
  year = {2022},
  month = jun,
  journal = {International Journal of Epidemiology},
  volume = {51},
  number = {3},
  pages = {931--944},
  issn = {0300-5771},
  doi = {10.1093/ije/dyab258},
  urldate = {2025-03-07},
  abstract = {Machine learning-based risk prediction models may outperform traditional statistical models in large datasets with many variables, by identifying both novel predictors and the complex interactions between them. This study compared deep learning extensions of survival analysis models with Cox proportional hazards models for predicting cardiovascular disease (CVD) risk in national health administrative datasets.Using individual person linkage of administrative datasets, we constructed a cohort of all New Zealanders aged 30--74\,who interacted with public health services during 2012. After excluding people with prior CVD, we developed sex-specific deep learning and Cox proportional hazards models to estimate the risk of CVD events within 5 years. Models were compared based on the proportion of explained variance, model calibration and discrimination, and hazard ratios for predictor variables.First CVD events occurred in 61\,927 of 2\,164\,872 people. Within the reference group, the largest hazard ratios estimated by the deep learning models were for tobacco use in women (2.04, 95\% CI: 1.99, 2.10) and chronic obstructive pulmonary disease with acute lower respiratory infection in men (1.56, 95\% CI: 1.50, 1.62). Other identified predictors (e.g. hypertension, chest pain, diabetes) aligned with current knowledge about CVD risk factors. Deep learning outperformed Cox proportional hazards models on the basis of proportion of explained variance (R2: 0.468 vs 0.425 in women and 0.383 vs 0.348 in men), calibration and discrimination (all P\,\&lt;0.0001).Deep learning extensions of survival analysis models can be applied to large health administrative datasets to derive interpretable CVD risk prediction equations that are more accurate than traditional Cox proportional hazards models.},
  file = {/Users/jason.brunson/Zotero/storage/2M686KLN/Barbieri et al. - 2022 - Predicting cardiovascular risk from national admin.pdf;/Users/jason.brunson/Zotero/storage/2XZ5GCLR/6463074.html}
}

@article{Begum2011,
  title = {Case-Based Reasoning Systems in the Health Sciences: A Survey of Recent Trends and Developments},
  shorttitle = {Case-Based Reasoning Systems in the Health Sciences},
  author = {Begum, Shahina and Ahmed, Mobyen Uddin and Funk, Peter and Xiong, Ning and Folke, Mia},
  year = {2011},
  month = jul,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume = {41},
  number = {4},
  pages = {421--434},
  issn = {1094-6977, 1558-2442},
  doi = {10.1109/TSMCC.2010.2071862},
  urldate = {2021-03-15}
}

@misc{Bellet2014,
  title = {A Survey on Metric Learning for Feature Vectors and Structured Data},
  author = {Bellet, Aur{\'e}lien and Habrard, Amaury and Sebban, Marc},
  year = {2014},
  month = feb,
  number = {arXiv:1306.6709},
  eprint = {1306.6709},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1306.6709},
  urldate = {2022-09-20},
  abstract = {The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{Benchimol2015,
  title = {The REporting of Studies Conducted Using Observational Routinely-Collected Health Data (RECORD) Statement},
  author = {Benchimol, Eric I. and Smeeth, Liam and Guttmann, Astrid and Harron, Katie and Moher, David and Petersen, Irene and S{\o}rensen, Henrik T. and {\noopsort{elm}}von Elm, Erik and Langan, Sin{\'e}ad M. and Committee, RECORD Working},
  year = {2015},
  month = oct,
  journal = {PLOS Medicine},
  volume = {12},
  number = {10},
  pages = {e1001885},
  publisher = {Public Library of Science},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1001885},
  urldate = {2025-03-07},
  abstract = {Routinely collected health data, obtained for administrative and clinical purposes without specific a priori research goals, are increasingly used for research. The rapid evolution and availability of these data have revealed issues not addressed by existing reporting guidelines, such as Strengthening the Reporting of Observational Studies in Epidemiology (STROBE). The REporting of studies Conducted using Observational Routinely collected health Data (RECORD) statement was created to fill these gaps. RECORD was created as an extension to the STROBE statement to address reporting items specific to observational studies using routinely collected health data. RECORD consists of a checklist of 13 items related to the title, abstract, introduction, methods, results, and discussion section of articles, and other information required for inclusion in such research reports. This document contains the checklist and explanatory and elaboration information to enhance the use of the checklist. Examples of good reporting for each RECORD checklist item are also included herein. This document, as well as the accompanying website and message board (http://www.record-statement.org), will enhance the implementation and understanding of RECORD. Through implementation of RECORD, authors, journals editors, and peer reviewers can encourage transparency of research reporting.},
  langid = {english},
  keywords = {Data management,Database and informatics methods,Internet,Medical risk factors,Observational studies,Peer review,Research design,Research reporting guidelines},
  file = {/Users/jason.brunson/Zotero/storage/76IQ8B2I/Benchimol et al. - 2015 - The REporting of studies Conducted using Observati.pdf}
}

@article{Bichindaritz2006,
  title = {Case-Based Reasoning in the Health Sciences: What's Next?},
  shorttitle = {Case-Based Reasoning in the Health Sciences},
  author = {Bichindaritz, Isabelle and Marling, Cindy},
  year = {2006},
  month = feb,
  journal = {Artificial Intelligence in Medicine},
  series = {Case-Based Reasoning in the Health Sciences},
  volume = {36},
  number = {2},
  pages = {127--135},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2005.10.008},
  urldate = {2022-01-31},
  abstract = {Objectives This paper presents current work in case-based reasoning (CBR) in the health sciences, describes current trends and issues, and projects future directions for work in this field. Methods and material It represents the contributions of researchers at two workshops on case-based reasoning in the health sciences. These workshops were held at the Fifth International Conference on Case-Based Reasoning (ICCBR-03) and the Seventh European Conference on Case-Based Reasoning (ECCBR-04). Results Current research in CBR in the health sciences is marked by its richness. Highlighted trends include work in bioinformatics, support to the elderly and people with disabilities, formalization of CBR in biomedicine, and feature and case mining. Conclusion CBR systems are being better designed to account for the complexity of biomedicine, to integrate into clinical settings and to communicate and interact with diverse systems and methods.},
  langid = {english},
  keywords = {Artificial intelligence in medicine,Bioinformatics,Case-based reasoning,Medical informatics},
  file = {/Users/jason.brunson/Zotero/storage/5RJW7KL2/Bichindaritz and Marling - 2006 - Case-based reasoning in the health sciences What'.pdf}
}

@book{Biecek2021,
  title = {Explanatory Model Analysis: Explore, Explain, and Examine Predictive Models},
  author = {Biecek, Przemyslaw and Burzykowski, Tomasz},
  year = {2021},
  publisher = {{Chapman and Hall/CRC}},
  address = {New York},
  urldate = {2023-09-08},
  abstract = {This book introduces unified language for exploration, explanation and examination of predictive machine learning models.},
  isbn = {978-0-367-13559-1}
}

@incollection{Blanco2013,
  title = {Case-Based Reasoning Applied to Medical Diagnosis and Treatment},
  booktitle = {Distributed Computing and Artificial Intelligence},
  author = {Blanco, Xiomara and Rodr{\'i}guez, Sara and Corchado, Juan M. and Zato, Carolina},
  editor = {Omatu, Sigeru and Neves, Jos{\'e} and Rodriguez, Juan M. Corchado and Paz Santana, Juan F and Gonzalez, Sara Rodr{\'i}guez},
  year = {2013},
  volume = {217},
  pages = {137--146},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-00551-5_17},
  urldate = {2021-03-15},
  isbn = {978-3-319-00550-8 978-3-319-00551-5}
}

@article{Brauneck2023,
  title = {Federated Machine Learning, Privacy-Enhancing Technologies, and Data Protection Laws in Medical Research: Scoping Review},
  shorttitle = {Federated Machine Learning, Privacy-Enhancing Technologies, and Data Protection Laws in Medical Research},
  author = {Brauneck, Alissa and Schmalhorst, Louisa and Majdabadi, Mohammad Mahdi Kazemi and Bakhtiari, Mohammad and V{\"o}lker, Uwe and Baumbach, Jan and Baumbach, Linda and Buchholtz, Gabriele},
  year = {2023},
  month = mar,
  journal = {Journal of Medical Internet Research},
  volume = {25},
  number = {1},
  pages = {e41588},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  doi = {10.2196/41588},
  urldate = {2023-08-21},
  abstract = {Background: The collection, storage, and analysis of large data sets are relevant in many sectors. Especially in the medical field, the processing of patient data promises great progress in personalized health care. However, it is strictly regulated, such as by the General Data Protection Regulation (GDPR). These regulations mandate strict data security and data protection and, thus, create major challenges for collecting and using large data sets. Technologies such as federated learning (FL), especially paired with differential privacy (DP) and secure multiparty computation (SMPC), aim to solve these challenges. Objective: This scoping review aimed to summarize the current discussion on the legal questions and concerns related to FL systems in medical research. We were particularly interested in whether and to what extent FL applications and training processes are compliant with the GDPR data protection law and whether the use of the aforementioned privacy-enhancing technologies (DP and SMPC) affects this legal compliance. We placed special emphasis on the consequences for medical research and development. Methods: We performed a scoping review according to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews). We reviewed articles on Beck-Online, SSRN, ScienceDirect, arXiv, and Google Scholar published in German or English between 2016 and 2022. We examined 4 questions: whether local and global models are ``personal data'' as per the GDPR; what the ``roles'' as defined by the GDPR of various parties in FL are; who controls the data at various stages of the training process; and how, if at all, the use of privacy-enhancing technologies affects these findings. Results: We identified and summarized the findings of 56 relevant publications on FL. Local and likely also global models constitute personal data according to the GDPR. FL strengthens data protection but is still vulnerable to a number of attacks and the possibility of data leakage. These concerns can be successfully addressed through the privacy-enhancing technologies SMPC and DP. Conclusions: Combining FL with SMPC and DP is necessary to fulfill the legal data protection requirements (GDPR) in medical research dealing with personal data. Even though some technical and legal challenges remain, for example, the possibility of successful attacks on the system, combining FL with SMPC and DP creates enough security to satisfy the legal requirements of the GDPR. This combination thereby provides an attractive technical solution for health institutions willing to collaborate without exposing their data to risk. From a legal perspective, the combination provides enough built-in security measures to satisfy data protection requirements, and from a technical perspective, the combination provides secure systems with comparable performance with centralized machine learning applications.},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/39MP3LMI/Brauneck et al. - 2023 - Federated Machine Learning, Privacy-Enhancing Tech.pdf;/Users/jason.brunson/Zotero/storage/8UH3WZIJ/e41588.html}
}

@article{Brown2016,
  title = {Patient Similarity: Emerging Concepts in Systems and Precision Medicine},
  shorttitle = {Patient Similarity},
  author = {Brown, Sherry-Ann},
  year = {2016},
  month = nov,
  journal = {Frontiers in Physiology},
  volume = {7},
  pages = {561},
  issn = {1664-042X},
  doi = {10.3389/fphys.2016.00561},
  urldate = {2021-03-15},
  file = {/Users/jason.brunson/Zotero/storage/296P8PB6/Brown - 2016 - Patient Similarity Emerging Concepts in Systems a.pdf}
}

@article{Cassimatis2010,
  title = {An Architecture for Adaptive Algorithmic Hybrids},
  author = {Cassimatis, Nicholas and Bignoli, Perrin and Bugajska, Magdalena and Dugas, Scott and Kurup, Unmesh and Murugesan, Arthi and Bello, Paul},
  year = {2010},
  month = jun,
  journal = {IEEE Trans Syst Man Cybern B Cybern},
  volume = {40},
  number = {3},
  pages = {903--914},
  issn = {1941-0492 1083-4419},
  doi = {10.1109/TSMCB.2009.2033262},
  abstract = {We describe a cognitive architecture for creating more robust intelligent systems. Our approach is to enable hybrids of algorithms based on different computational formalisms to be executed. The architecture is motivated by some features of human cognitive architecture and the following beliefs: 1) Most existing computational methods often exhibit some of the characteristics desired of intelligent systems at the cost of other desired characteristics and 2) a system exhibiting robust intelligence can be designed by implementing hybrids of these computational methods. The main obstacle to this approach is that the various relevant computational methods are based on data structures and algorithms that are difficult to integrate into one system. We describe a new method of executing hybrids of algorithms using the focus of attention of multiple modules. The key to this approach is the following two principles: 1) Algorithms based on very different computational frameworks (e.g., logical reasoning, probabilistic inference, and case-based reasoning) can be implemented using the same set of five common functions and 2) each of these common functions can be executed using multiple data structures and algorithms. This approach has been embodied in the Polyscheme cognitive architecture. Systems based on Polyscheme in planning, spatial reasoning, robotics, and information retrieval illustrate that this approach to hybridizing algorithms enables qualitative and measurable quantitative advances in the abilities of intelligent systems.},
  langid = {english},
  keywords = {{*Models, Theoretical},{Pattern Recognition, Automated/*methods},*Algorithms,*Artificial Intelligence,*Decision Support Techniques,Cognitive robotics,Computational intelligence,Computer architecture,Computer Simulation,Costs,Data structures,Humans,Hybrid architectures,Hybrid intelligent systems,Inference algorithms,integrated systems,Intelligent robots,Robustness},
  file = {/Users/jason.brunson/Zotero/storage/CB4XN37Y/Cassimatis et al. - 2010 - An Architecture for Adaptive Algorithmic Hybrids.pdf}
}

@article{Choudhury2016,
  title = {A Survey on Case-Based Reasoning in Medicine},
  author = {Choudhury, Nabanita and Begum, Shahin Ara},
  year = {2016},
  journal = {International Journal of Advanced Computer Science and Applications},
  volume = {7},
  number = {8},
  issn = {21565570, 2158107X},
  doi = {10.14569/IJACSA.2016.070820},
  urldate = {2021-03-15},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/GC2P9CCT/Choudhury and Begum - 2016 - A Survey on Case-based Reasoning in Medicine.pdf}
}

@article{Dai2020,
  title = {Patient Similarity: Methods and Applications},
  shorttitle = {Patient Similarity},
  author = {Dai, Leyu and Zhu, He and Liu, Dianbo},
  year = {2020},
  month = dec,
  journal = {arXiv:2012.01976 [cs]},
  eprint = {2012.01976},
  primaryclass = {cs},
  urldate = {2021-03-15},
  abstract = {Patient similarity analysis is important in health care applications. It takes patient information such as their electronic medical records and genetic data as input and computes the pairwise similarity between patients. Procedures of typical a patient similarity study can be divided into several steps including data integration, similarity measurement, and neighborhood identification. And according to an analysis of patient similarity, doctors can easily find the most suitable treatments. There are many methods to analyze the similarity such as cluster analysis. And during machine learning become more and more popular, Using neural networks such as CNN is a new hot topic. This review summarizes representative methods used in each step and discusses applications of patient similarity networks especially in the context of precision medicine.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@article{Elhaddad2024,
  title = {AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential},
  shorttitle = {AI-Driven Clinical Decision Support Systems},
  author = {Elhaddad, Malek and Hamam, Sara and Elhaddad, Malek and Hamam, Sara},
  year = {2024},
  month = apr,
  journal = {Cureus},
  volume = {16},
  number = {4},
  publisher = {Cureus},
  issn = {2168-8184},
  doi = {10.7759/cureus.57728},
  urldate = {2025-03-07},
  abstract = {Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing~obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/UKHHN8FR/Elhaddad et al. - 2024 - AI-Driven Clinical Decision Support Systems An On.pdf}
}

@incollection{Gierl1998,
  title = {CBR in Medicine},
  booktitle = {Case-Based Reasoning Technology},
  author = {Gierl, Lothar and Bull, Mathias and Schmidt, Rainer},
  editor = {Lenz, Mario and Burkhard, Hans-Dieter and {Bartsch-Sp{\"o}rl}, Brigitte and Wess, Stefan},
  year = {1998},
  volume = {1400},
  pages = {273--297},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-69351-3_11},
  urldate = {2021-03-15},
  isbn = {978-3-540-64572-6 978-3-540-69351-2},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/V5B274KQ/Gierl et al. - 1998 - CBR in Medicine.pdf}
}

@inproceedings{Goyal2008,
  title = {Disorder Inequality: A Combinatorial Approach to Nearest Neighbor Search},
  shorttitle = {Disorder Inequality},
  booktitle = {Proceedings of the 2008 International Conference on Web Search and Data Mining},
  author = {Goyal, Navin and Lifshits, Yury and Sch{\"u}tze, Hinrich},
  year = {2008},
  month = feb,
  series = {WSDM '08},
  pages = {25--32},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1341531.1341538},
  urldate = {2023-08-19},
  abstract = {We say that an algorithm for nearest neighbor search is combinatorial if only direct comparisons between two pairwise similarity values are allowed. Combinatorial algorithms for nearest neighbor search have two important advantages: (1) they do not map similarity values to artificial distance values and do not use the triangle inequality for the latter, and (2) they work for arbitrarily complicated data representations and similarity functions. In this paper we introduce a special property of the similarity function on a set S that leads to efficient combinatorial algorithms for S. The disorder constant D(S) of a set S is defined to ensure the following inequality: if x is the a'th most similar object to z and y is the b'th most similar object to z, then x is among the D(S) (a + b) most similar objects to y. Assuming that disorder is small we present the first two known combinatorial algorithms for nearest neighbors whose query time has logarithmic dependence on the size of S. The first one, called Ranwalk, is a randomized zero-error algorithm that always returns the exact nearest neighbor. It uses space quadratic in the input size in preprocessing, but is very efficient in query processing. The second algorithm, called Arwalk, uses near-linear space. It uses random choices in preprocessing, but the query processing is essentially deterministic. For an arbitrary query q, there is only a small probability that the chosen data structure does not support q Finally, we show that for the Reuters corpus average disorder is indeed quite small and that Ranwalk efficiently computes the nearest neighbor in most cases.},
  isbn = {978-1-59593-927-2},
  keywords = {disorder constant,disorder dimension,disorder inequality,nearest neighbor search,proximity search,random walk,randomized algorithms,similarity search},
  file = {/Users/jason.brunson/Zotero/storage/98SKGSL9/Goyal et al. - 2008 - Disorder inequality a combinatorial approach to n.pdf}
}

@article{Halder2024,
  title = {Enhancing K-Nearest Neighbor Algorithm: A Comprehensive Review and Performance Analysis of Modifications},
  shorttitle = {Enhancing K-Nearest Neighbor Algorithm},
  author = {Halder, Rajib Kumar and Uddin, Mohammed Nasir and Uddin, Md. Ashraf and Aryal, Sunil and Khraisat, Ansam},
  year = {2024},
  month = aug,
  journal = {Journal of Big Data},
  volume = {11},
  number = {1},
  pages = {113},
  issn = {2196-1115},
  doi = {10.1186/s40537-024-00973-y},
  urldate = {2025-03-07},
  abstract = {The k-Nearest Neighbors (kNN) method, established in 1951, has since evolved into a pivotal tool in data mining, recommendation systems, and Internet of Things (IoT), among other areas. This paper presents a comprehensive review and performance analysis of modifications made to enhance the exact kNN techniques, particularly focusing on kNN Search and kNN Join for high-dimensional data. We delve deep into 31 kNN search methods and 12 kNN join methods, providing a methodological overview and analytical insight into each, emphasizing their strengths, limitations, and applicability. An important feature of our study is the provision of the source code for each of the kNN methods discussed, fostering ease of experimentation and comparative analysis for readers. Motivated by the rising significance of kNN in high-dimensional spaces and a recognized gap in comprehensive surveys on exact kNN techniques, our work seeks to bridge this gap. Additionally, we outline existing challenges and present potential directions for future research in the domain of kNN techniques, offering a holistic guide that amalgamates, compares, and dissects existing methodologies in a coherent manner.},
  keywords = {Exact K-nearest neighbors,High dimensional data,K-nearest neighbors join,K-nearest neighbors search,Performance analysis},
  file = {/Users/jason.brunson/Zotero/storage/UK774GNW/Halder et al. - 2024 - Enhancing K-nearest neighbor algorithm a comprehe.pdf}
}

@article{Holmqvist2015,
  title = {Developing Practice-Based Evidence: Benefits, Challenges, and Tensions},
  shorttitle = {Developing Practice-Based Evidence},
  author = {Holmqvist, Rolf and Philips, Bj{\"o}rn and Barkham, Michael},
  year = {2015},
  month = jan,
  journal = {Psychotherapy Research},
  volume = {25},
  number = {1},
  pages = {20--31},
  publisher = {Routledge},
  issn = {1050-3307},
  doi = {10.1080/10503307.2013.861093},
  urldate = {2025-03-06},
  abstract = {Attempts to regulate service delivery in line with results from randomized trials have been vigorously debated. In this paper, results from practice-based studies using the CORE System illustrate the potential to enrich knowledge about the actual outcome of psychological therapy in routine care. These studies also provide data for important questions in psychotherapy research, like orientation differences, the importance of the therapist factor, number of sessions needed for clinical effect, and the alliance--outcome question. Obstacles and challenges in making such studies are illustrated. In conclusion, arguments are put forward for introducing a common measurement system that strikes a balance between clinicians' questions and the need for comparable data, and that encompasses the complexities of patients' reasons for seeking psychological help.},
  pmid = {24283264},
  keywords = {mental health services research,outcome research},
  file = {/Users/jason.brunson/Zotero/storage/LNM9WVH9/Holmqvist et al. - 2015 - Developing practice-based evidence Benefits, chal.pdf}
}

@incollection{Jenhani2010,
  title = {Possibilistic Similarity Measures},
  booktitle = {Foundations of Reasoning under Uncertainty},
  author = {Jenhani, Ilyes and Benferhat, Salem and Elouedi, Zied},
  editor = {{Bouchon-Meunier}, Bernadette and Magdalena, Luis and {Ojeda-Aciego}, Manuel and Verdegay, Jos{\'e}-Luis and Yager, Ronald R.},
  year = {2010},
  series = {Studies in Fuzziness and Soft Computing},
  pages = {99--123},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-10728-3_6},
  urldate = {2021-12-21},
  abstract = {This paper investigates the problem of measuring the similarity degree between two normalized possibility distributions encoding preferences or uncertain knowledge. In a first part, basic natural properties of such similarity measures are proposed. Then a survey of the existing possibilistic similarity indexes is presented and in particular, we analyze which existing similarity measure satisfies the set of basic properties. The second part of this paper goes one step further and provides a set of extended properties that any similarity relation should satisfy. Finally, some definitions of possibilistic similarity measures that involve inconsistency degrees between possibility distributions are discussed.},
  isbn = {978-3-642-10728-3},
  langid = {english},
  keywords = {Basic Probability Assignment,Possibility Degree,Possibility Distribution,Possibility Theory,Similarity Measure}
}

@article{Kaltoft2016,
  title = {Towards Integrating the Principlist and Casuist Approaches to Ethical Decisions via Multi-Criterial Support},
  author = {Kaltoft, Mette Kjer and Nielsen, Jesper Bo and Salkeld, Glenn and Dowie, Jack},
  year = {2016},
  journal = {Stud Health Technol Inform},
  volume = {225},
  pages = {540--544},
  publisher = {IOS Press},
  issn = {1879-8365 0926-9630},
  doi = {10.3233/978-1-61499-658-3-540},
  urldate = {2021-12-20},
  abstract = {An interactive decision support tool based on Multi-Criteria Decision Analysis (MCDA) can help health professionals integrate the principlist (principle-based) and  casuist (case-based) approaches to ethical decision making in both their training  and practice. MCDA can incorporate generic ethical principles as criteria; then draw  on case-based reasoning as the basis for specifying, in the individual case, the  available options, the ratings of each option on each criterion, and the relative  weighting of the criteria. This produces a personalised, transparent and  decomposable opinion on the merits of each option, as a contribution to enhanced  deliberation. As proof of concept and method an exemplar aid adds veracity and  confidentiality to beneficence, non-maleficence, autonomy and justice, as the  criteria, with case-based reasoning supplying the necessary inputs for the decision  of whether a nurse should disclose the poor prognosis of a patient to a close  relative of the patient, when asked, on their first encounter.},
  langid = {english},
  keywords = {{*Ethics, Nursing},{Decision Support Systems, Clinical/*ethics/*organization \& administration},{Delivery of Health Care, Integrated/ethics/methods},Clinical Decision-Making/*ethics/*methods,Decision Making/ethics,Nursing Assessment/*ethics/methods},
  file = {/Users/jason.brunson/Zotero/storage/6J2YSSQ3/Kaltoft et al. - 2016 - Towards Integrating the Principlist and Casuist Ap.pdf}
}

@article{Kolodner1992,
  title = {An Introduction to Case-Based Reasoning},
  author = {Kolodner, Janet L.},
  year = {1992},
  month = mar,
  journal = {Artif Intell Rev},
  volume = {6},
  number = {1},
  pages = {3--34},
  issn = {1573-7462},
  doi = {10.1007/BF00155578},
  urldate = {2021-11-14},
  abstract = {Case-based reasoning means using old experiences to understand and solve new problems. In case-based reasoning, a reasoner remembers a previous situation similar to the current one and uses that to solve the new problem. Case-based reasoning can mean adapting old solutions to meet new demands; using old cases to explain new situations; using old cases to critique new solutions; or reasoning from precedents to interpret a new situation (much like lawyers do) or create an equitable solution to a new problem (much like labor mediators do). This paper discusses the processes involved in case-based reasoning and the tasks for which case-based reasoning is useful.},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/Y5HES6F3/Kolodner - 1992 - An introduction to case-based reasoning.pdf}
}

@inproceedings{Lanners2023,
  title = {Variable Importance Matching for Causal Inference},
  booktitle = {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},
  author = {Lanners, Quinn and Parikh, Harsh and Volfovsky, Alexander and Rudin, Cynthia and Page, David},
  year = {2023},
  month = jul,
  pages = {1174--1184},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-03-07},
  abstract = {Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, yield accurate treatment effect estimates, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the auditability of matches, as well as extensions to more general nonparametric outcome modeling.},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/HVNMICN6/Lanners et al. - 2023 - Variable importance matching for causal inference.pdf;/Users/jason.brunson/Zotero/storage/LJR685UJ/Lanners et al. - 2023 - Variable importance matching for causal inference.pdf}
}

@incollection{Liu2019,
  title = {Precision Delivery in Critical Care: Balancing Prediction and Personalization},
  shorttitle = {Precision Delivery in Critical Care},
  booktitle = {Annual Update in Intensive Care and Emergency Medicine 2019},
  author = {Liu, V. X. and Prescott, H. C.},
  editor = {Vincent, Jean-Louis},
  year = {2019},
  series = {Annual Update in Intensive Care and Emergency Medicine},
  pages = {15--27},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-06067-1_2},
  urldate = {2021-12-23},
  abstract = {Recent developments in healthcare data availability, advanced analytic algorithms, and high-performance computing have produced incredible enthusiasm about a new age of data-driven healthcare [1--8]. When it comes to clinical care specifically, `precision delivery' is an emerging term to describe the ``routine use of patients' electronic health record (EHR) data to predict risk and personalize care to substantially improve value'' (Table 2.1) [7, 9, 10]. While clinical risk prediction tools have a long history in critical care, novel machine learning applications can offer improved predictive performance by maximally leveraging large-scale, complex EHR and other data [5]. Perhaps, even more importantly, these approaches may help overcome the problem of heterogeneity, which is routinely noted to be a hallmark of critical illness as well as a major barrier to improved treatment [11--13]. In this chapter, we discuss the overarching concept of `precision delivery', the important balance between clinical risk prediction and personalization, and the future challenges and applications of data-driven critical care delivery.},
  isbn = {978-3-030-06067-1},
  langid = {english}
}

@article{Longhurst2014,
  title = {A `Green Button' For Using Aggregate Patient Data At The Point Of Care},
  author = {Longhurst, Christopher A. and Harrington, Robert A. and Shah, Nigam H.},
  year = {2014},
  month = jul,
  journal = {Health Affairs},
  volume = {33},
  number = {7},
  pages = {1229--1235},
  publisher = {Health Affairs},
  issn = {0278-2715},
  doi = {10.1377/hlthaff.2014.0099},
  urldate = {2021-04-13},
  abstract = {Randomized controlled trials have traditionally been the gold standard against which all other sources of clinical evidence are measured. However, the cost of conducting these trials can be prohibitive. In addition, evidence from the trials frequently rests on narrow patient-inclusion criteria and thus may not generalize well to real clinical situations. Given the increasing availability of comprehensive clinical data in electronic health records (EHRs), some health system leaders are now advocating for a shift away from traditional trials and toward large-scale retrospective studies, which can use practice-based evidence that is generated as a by-product of clinical processes. Other thought leaders in clinical research suggest that EHRs should be used to lower the cost of trials by integrating point-of-care randomization and data capture into clinical processes. We believe that a successful learning health care system will require both approaches, and we suggest a model that resolves this escalating tension: a ``green button'' function within EHRs to help clinicians leverage aggregate patient data for decision making at the point of care. Giving clinicians such a tool would support patient care decisions in the absence of gold-standard evidence and would help prioritize clinical questions for which EHR-enabled randomization should be carried out. The privacy rule in the Health Insurance Portability and Accountability Act (HIPAA) of 1996 may require revision to support this novel use of patient data.}
}

@article{Maglo2012,
  title = {Group-Based and Personalized Care in an Age of Genomic and Evidence-Based Medicine: A Reappraisal},
  shorttitle = {Group-Based and Personalized Care in an Age of Genomic and Evidence-Based Medicine},
  author = {Maglo, Koffi N.},
  year = {2012},
  journal = {Perspectives in Biology and Medicine},
  volume = {55},
  number = {1},
  pages = {137--154},
  publisher = {Johns Hopkins University Press},
  issn = {1529-8795},
  doi = {10.1353/pbm.2012.0006},
  urldate = {2022-01-31},
  abstract = {This article addresses the philosophical and moral foundations of group-based and individualized therapy in connection with population care equality. The U.S. Food and Drug Administration (FDA) recently modified its public health policy by seeking to enhance the efficacy and equality of care through the approval of group-specific prescriptions and doses for some drugs. In the age of genomics, when individualization of care increasingly has become a major concern, investigating the relationship between population health, stratified medicine, and personalized therapy can improve our understanding of the ethical and biomedical implications of genomic medicine. I suggest that the need to optimize population health through population substructure-sensitive research and the need to individualize care through genetically targeted therapies are not necessarily incompatible. Accordingly, the article reconceptualizes a unified goal for modern scientific medicine in terms of individualized equal care.  [End Page 137]}
}

@article{Matarese2022,
  title = {Kinds of Replicability: Different Terms and Different Functions},
  shorttitle = {Kinds of Replicability},
  author = {Matarese, Vera},
  year = {2022},
  month = dec,
  journal = {Axiomathes},
  volume = {32},
  number = {2},
  pages = {647--670},
  issn = {1572-8390},
  doi = {10.1007/s10516-021-09610-2},
  urldate = {2023-09-08},
  abstract = {Replicability is usually considered to be one of the cornerstones of science; however, the growing recognition of nonreplicable experiments and studies in scientific journals---a phenomenon that has been called `replicability crisis'---has spurred a debate on the meaning, function, and significance of replicability in science. Amid this discussion, it has become clear that replicability is not a monolithic concept; what is still controversial is exactly how the distinction between different kinds of replicability should be laid out terminologically and conceptually, and to what extent it bears on the more general debate on the centrality of replicability in science. This paper's goals are to clarify the different uses of the terms related to replicability and, more importantly, to conceptually specify the kinds of replicability and their respective epistemic functions.},
  langid = {english},
  keywords = {Accuracy,Conceptual replicability,Direct replicability,Method reproducibility,Precision,Reliability,Replicability,Replicability crisis,Reproducibility,Validity},
  file = {/Users/jason.brunson/Zotero/storage/ZYRGTV6Y/Matarese - 2022 - Kinds of Replicability Different Terms and Differ.pdf}
}

@book{Molnar2023,
  title = {Interpretable Machine Learning: A Guide for Making Black Box Models Explainable},
  author = {Molnar, Christoph},
  year = {2023},
  month = aug,
  urldate = {2023-09-08},
  abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.}
}

@article{Montani2011,
  title = {How to Use Contextual Knowledge in Medical Case-Based Reasoning Systems: A Survey on Very Recent Trends},
  shorttitle = {How to Use Contextual Knowledge in Medical Case-Based Reasoning Systems},
  author = {Montani, Stefania},
  year = {2011},
  month = feb,
  journal = {Artif Intell Med},
  series = {Advances in Case-Based Reasoning in the Health Sciences},
  volume = {51},
  number = {2},
  pages = {125--131},
  issn = {1873-2860 0933-3657},
  doi = {10.1016/j.artmed.2010.09.004},
  urldate = {2021-12-23},
  abstract = {Objectives This paper aims at systematizing the ways in which the contextual knowledge embedded in the case library can support decision making, within case-based reasoning (CBR) systems. In particular, CBR applications to the medical domain are considered. Methods and material After a quick survey on the definition and on the role of context in artificial intelligence research, we have focused on CBR, with a particular emphasis on medical applications. In this field, we have identified a number of very recent contributions, which strongly recognize context per se as a major knowledge source. These contributions propose to maintain and to rely on contextual information, in order to support human reasoning in different fashions. Results We have distinguished three main directions in which contextual knowledge can be resorted to, in order to optimize physicians' decision making. Such directions can be summarized as follows: (1) to reduce the search space in the case retrieval step; (2) to maintain the overall knowledge content always valid and up to date, and (3) to adapt knowledge application and reasoning to local/personal constraints. We have also properly categorized the surveyed works within these three clusters, and identified the most significant ones, able to exploit contextual knowledge along more than one direction. Conclusions Innovative applications of the contextual knowledge recorded in the case library, described and systematized in this paper, can trace promising research directions for the future.},
  langid = {english},
  keywords = {{*Decision Support Systems, Clinical/trends},*Artificial Intelligence,*Data Mining/trends,Case-based reasoning,Computer Graphics,Context,Decision Support Techniques,Diffusion of Innovation,Humans,Knowledge and reasoning adaptation,Knowledge Bases,Knowledge validity,Medical Informatics/*methods/trends,Retrieval efficiency,Systems Integration,User-Computer Interface}
}

@article{Moshawrab2023,
  title = {Reviewing Federated Machine Learning and Its Use in Diseases Prediction},
  author = {Moshawrab, Mohammad and Adda, Mehdi and Bouzouane, Abdenour and Ibrahim, Hussein and Raad, Ali},
  year = {2023},
  month = jan,
  journal = {Sensors},
  volume = {23},
  number = {4},
  pages = {2112},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1424-8220},
  doi = {10.3390/s23042112},
  urldate = {2023-08-21},
  abstract = {Machine learning (ML) has succeeded in improving our daily routines by enabling automation and improved decision making in a variety of industries such as healthcare, finance, and transportation, resulting in increased efficiency and production. However, the development and widespread use of this technology has been significantly hampered by concerns about data privacy, confidentiality, and sensitivity, particularly in healthcare and finance. The ``data hunger'' of ML describes how additional data can increase performance and accuracy, which is why this question arises. Federated learning (FL) has emerged as a technology that helps solve the privacy problem by eliminating the need to send data to a primary server and collect it where it is processed and the model is trained. To maintain privacy and improve model performance, FL shares parameters rather than data during training, in contrast to the typical ML practice of sending user data during model development. Although FL is still in its infancy, there are already applications in various industries such as healthcare, finance, transportation, and others. In addition, 32\% of companies have implemented or plan to implement federated learning in the next 12--24 months, according to the latest figures from KPMG, which forecasts an increase in investment in this area from USD 107 million in 2020 to USD 538 million in 2025. In this context, this article reviews federated learning, describes it technically, differentiates it from other technologies, and discusses current FL aggregation algorithms. It also discusses the use of FL in the diagnosis of cardiovascular disease, diabetes, and cancer. Finally, the problems hindering progress in this area and future strategies to overcome these limitations are discussed in detail.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {aggregation algorithms,cancer,cardiovascular diseases,diabetes,diseases prediction,federated learning,federated machine learning,privacy preservation,smart health,smart wearables},
  file = {/Users/jason.brunson/Zotero/storage/KXSCNV29/Moshawrab et al. - 2023 - Reviewing Federated Machine Learning and Its Use i.pdf}
}

@inproceedings{Nilsson2004,
  title = {Advancement and Trends in Medical Case-Based Reasoning: An Overview of Systems and System Development},
  booktitle = {Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2004},
  author = {Nilsson, Markus and Sollenborn, Mikael},
  year = {2004},
  month = may,
  pages = {178--183},
  address = {Miami Beach, FL, USA},
  urldate = {2021-03-26},
  abstract = {Case-Based Reasoning (CBR) is a recognised and well established method for building medical systems. In this paper, we identify strengths and weaknesses of CBR in medicine. System properties, divided into construction-oriented and purpose-oriented, are used as the basis for a survey of recent publications and research projects. The survey is used to find current trends in present medical CBR research.}
}

@article{Parimbelli2018,
  title = {Patient Similarity for Precision Medicine: A Systematic Review},
  shorttitle = {Patient Similarity for Precision Medicine},
  author = {Parimbelli, E. and Marini, S. and Sacchi, L. and Bellazzi, R.},
  year = {2018},
  month = jul,
  journal = {Journal of Biomedical Informatics},
  volume = {83},
  pages = {87--96},
  issn = {15320464},
  doi = {10.1016/j.jbi.2018.06.001},
  urldate = {2021-03-15},
  langid = {english}
}

@article{Plesser2018,
  title = {Reproducibility vs. Replicability: A Brief History of a Confused Terminology},
  shorttitle = {Reproducibility vs. Replicability},
  author = {Plesser, Hans E.},
  year = {2018},
  journal = {Frontiers in Neuroinformatics},
  volume = {11},
  issn = {1662-5196},
  urldate = {2023-09-08},
  file = {/Users/jason.brunson/Zotero/storage/DQJ4M3R8/Plesser - 2018 - Reproducibility vs. Replicability A Brief History.pdf}
}

@inproceedings{Plumb2018,
  title = {Model Agnostic Supervised Local Explanations},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Plumb, Gregory and Molitor, Denali and Talwalkar, Ameet S},
  year = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  urldate = {2023-09-08},
  abstract = {Model interpretability is an increasingly important component of practical machine learning. Some of the most common forms of interpretability systems are example-based, local, and global explanations. One of the main challenges in interpretability is designing explanation systems that can capture aspects of each of these explanation types, in order to develop a more thorough understanding of the model. We address this challenge in a novel model called MAPLE that uses local linear modeling techniques along with a dual interpretation of random forests (both as a supervised neighborhood approach and as a feature selection method). MAPLE has two fundamental advantages over existing interpretability systems. First, while it is effective as a black-box explanation system, MAPLE itself is a highly accurate predictive model that provides faithful self explanations, and thus sidesteps the typical accuracy-interpretability trade-off. Specifically, we demonstrate, on several UCI datasets, that MAPLE is at least as accurate as random forests and that it produces more faithful local explanations than LIME, a popular interpretability system. Second, MAPLE provides both example-based and local explanations and can detect global patterns, which allows it to diagnose limitations in its local explanations.},
  file = {/Users/jason.brunson/Zotero/storage/YWF5BH7E/Plumb et al. - 2018 - Model Agnostic Supervised Local Explanations.pdf}
}

@article{PRISMASGroup2021,
  title = {PRISMA-S: An Extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews},
  shorttitle = {PRISMA-S},
  author = {{PRISMA-S Group} and Rethlefsen, Melissa L. and Kirtley, Shona and Waffenschmidt, Siw and Ayala, Ana Patricia and Moher, David and Page, Matthew J. and Koffel, Jonathan B.},
  year = {2021},
  month = dec,
  journal = {Syst Rev},
  volume = {10},
  number = {1},
  pages = {39},
  issn = {2046-4053},
  doi = {10.1186/s13643-020-01542-z},
  urldate = {2021-02-25},
  abstract = {Abstract                            Background               Literature searches underlie the foundations of systematic reviews and related review types. Yet, the literature searching component of systematic reviews and related review types is often poorly reported. Guidance for literature search reporting has been diverse, and, in many cases, does not offer enough detail to authors who need more specific information about reporting search methods and information sources in a clear, reproducible way. This document presents the PRISMA-S (Preferred Reporting Items for Systematic reviews and Meta-Analyses literature search extension) checklist, and explanation and elaboration.                                         Methods               The checklist was developed using a 3-stage Delphi survey process, followed by a consensus conference and public review process.                                         Results               The final checklist includes 16 reporting items, each of which is detailed with exemplar reporting and rationale.                                         Conclusions               The intent of PRISMA-S is to complement the PRISMA Statement and its extensions by providing a checklist that could be used by interdisciplinary authors, editors, and peer reviewers to verify that each component of a search is completely reported and therefore reproducible.},
  langid = {english}
}

@article{Rosella2022,
  title = {Commentary: Deep Learning Approaches Applied to Routinely Collected Health Data: Future Directions},
  shorttitle = {Commentary},
  author = {Rosella, Laura C},
  year = {2022},
  month = jun,
  journal = {International Journal of Epidemiology},
  volume = {51},
  number = {3},
  pages = {931--933},
  issn = {0300-5771},
  doi = {10.1093/ije/dyac064},
  urldate = {2025-03-07},
  abstract = {Prediction models have been a cornerstone of cardiovascular epidemiology for decades. Various types of methods have been tested for improvements in model performance, including machine learning models. In this issue of the International Journal of Epidemiology, Barbieri et al.1 combine survival methods with deep learning models to predict the 5-year risk of fatal or non-fatal cardiovascular events using nationally linked administrative databases. This study demonstrates two developments in health prediction research: the increasing use of linked administrative databases to generate predictive models and the application of deep learning methods to execute prediction tasks. The authors demonstrate that deep learning approaches can feasibly be applied to routinely collected administrative databases and suggest a performance advantage. What can we learn from studies that apply deep learning methods to health administrative data for prediction tasks? Moreover, what is needed to improve the application of deep learning methods for the prediction of cardiovascular and other health outcomes?},
  file = {/Users/jason.brunson/Zotero/storage/EHVY84ZG/Rosella - 2022 - Commentary Deep learning approaches applied to ro.pdf;/Users/jason.brunson/Zotero/storage/36VACTLC/6563085.html}
}

@article{Rudin2022,
  title = {Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges},
  shorttitle = {Interpretable Machine Learning},
  author = {Rudin, Cynthia and Chen, Chaofan and Chen, Zhi and Huang, Haiyang and Semenova, Lesia and Zhong, Chudi},
  year = {2022},
  month = jan,
  journal = {Statistics Surveys},
  volume = {16},
  number = {none},
  pages = {1--85},
  publisher = {{Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada}},
  issn = {1935-7516},
  doi = {10.1214/21-SS133},
  urldate = {2025-03-07},
  abstract = {Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the ``Rashomon set'' of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.},
  keywords = {62-02,68T01,explainable machine learning,Interpretable machine learning},
  file = {/Users/jason.brunson/Zotero/storage/9U397GRG/Rudin et al. - 2022 - Interpretable machine learning Fundamental princi.pdf}
}

@article{Sharafoddini2017,
  title = {Patient Similarity in Prediction Models Based on Health Data: A Scoping Review},
  shorttitle = {Patient Similarity in Prediction Models Based on Health Data},
  author = {Sharafoddini, Anis and Dubin, Joel A and Lee, Joon},
  year = {2017},
  month = mar,
  journal = {JMIR Medical Informatics},
  volume = {5},
  number = {1},
  pages = {e7},
  issn = {2291-9694},
  doi = {10.2196/medinform.6730},
  urldate = {2021-03-15},
  langid = {english},
  file = {/Users/jason.brunson/Zotero/storage/TGDT3PPL/Sharafoddini et al. - 2017 - Patient Similarity in Prediction Models Based on H.pdf}
}

@article{Sim2001,
  title = {Clinical Decision Support Systems for the Practice of Evidence-Based Medicine},
  author = {Sim, Ida and Gorman, Paul and Greenes, Robert A. and Haynes, R. Brian and Kaplan, Bonnie and Lehmann, Harold and Tang, Paul C.},
  year = {2001},
  month = nov,
  journal = {Journal of the American Medical Informatics Association},
  volume = {8},
  number = {6},
  pages = {527--534},
  issn = {1067-5027},
  doi = {10.1136/jamia.2001.0080527},
  urldate = {2025-03-07},
  abstract = {Background: The use of clinical decision support systems to facilitate the practice of evidence-based medicine promises to substantially improve health care quality.Objective: To describe, on the basis of the proceedings of the Evidence and Decision Support track at the 2000 AMIA Spring Symposium, the research and policy challenges for capturing research and practice-based evidence in machine-interpretable repositories, and to present recommendations for accelerating the development and adoption of clinical decision support systems for evidence-based medicine.Results: The recommendations fall into five broad areas---capture literature-based and practice-based evidence in machine-interpretable knowledge bases; develop maintainable technical and methodological foundations for computer-based decision support; evaluate the clinical effects and costs of clinical decision support systems and the ways clinical decision support systems affect and are affected by professional and organizational practices; identify and disseminate best practices for work flow--sensitive implementations of clinical decision support systems; and establish public policies that provide incentives for implementing clinical decision support systems to improve health care quality.Conclusions: Although the promise of clinical decision support system--facilitated evidence-based medicine is strong, substantial work remains to be done to realize the potential benefits.},
  file = {/Users/jason.brunson/Zotero/storage/XG969QCQ/Sim et al. - 2001 - Clinical Decision Support Systems for the Practice.pdf}
}

@article{Stange2009,
  title = {A Science of Connectedness},
  author = {Stange, Kurt C.},
  year = {2009},
  month = sep,
  journal = {The Annals of Family Medicine},
  volume = {7},
  number = {5},
  pages = {387--395},
  publisher = {The Annals of Family Medicine},
  issn = {1544-1709, 1544-1717},
  doi = {10.1370/afm.990},
  urldate = {2021-11-22},
  abstract = {How can health care reform approach the holy trinity of equitable access, controlled costs, and high value? How can the sweet spot be found in the midst of the politically charged and personally wrenching trade-offs? The sweet spot is where increasing access to health care creates a sense of},
  chapter = {Editorials},
  copyright = {{\copyright} 2009 Annals of Family Medicine, Inc.},
  langid = {english},
  pmid = {19752466},
  keywords = {{models, theoretical},delivery of health care,primary health care,Systems theory}
}

@article{Thackway2015,
  title = {Getting the Most from Routinely Collected Data},
  author = {Thackway, Sarah},
  year = {2015},
  month = sep,
  journal = {Public Health Res Pract},
  volume = {25},
  number = {4},
  pages = {e2541539},
  doi = {10.17061/phrp2541539},
  urldate = {2025-03-07},
  langid = {american},
  file = {/Users/jason.brunson/Zotero/storage/CMFQ4PDR/2015 - Getting the most from routinely collected data - S.pdf;/Users/jason.brunson/Zotero/storage/U8DISNGF/getting-the-most-from-routinely-collected-data.html}
}

@article{Thomas2008,
  title = {Methods for the Thematic Synthesis of Qualitative Research in Systematic Reviews},
  author = {Thomas, James and Harden, Angela},
  year = {2008},
  month = jul,
  journal = {BMC Medical Research Methodology},
  volume = {8},
  number = {1},
  pages = {45},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-8-45},
  urldate = {2022-03-27},
  abstract = {There is a growing recognition of the value of synthesising qualitative research in the evidence base in order to facilitate effective and appropriate health care. In response to this, methods for undertaking these syntheses are currently being developed. Thematic analysis is a method that is often used to analyse data in primary qualitative research. This paper reports on the use of this type of analysis in systematic reviews to bring together and integrate the findings of multiple qualitative studies.},
  keywords = {Analytical Theme,Healthy Eating,Primary Study,Qualitative Research,Review Question}
}

@article{Tranfield2003,
  title = {Towards a Methodology for Developing Evidence-Informed Management Knowledge by Means of Systematic Review},
  author = {Tranfield, David and Denyer, David and Smart, Palminder},
  year = {2003},
  journal = {British Journal of Management},
  volume = {14},
  number = {3},
  pages = {207--222},
  issn = {1467-8551},
  doi = {10.1111/1467-8551.00375},
  urldate = {2022-03-27},
  abstract = {Undertaking a review of the literature is an important part of any research project. The researcher both maps and assesses the relevant intellectual territory in order to specify a research question which will further develop the knowledge base. However, traditional `narrative' reviews frequently lack thoroughness, and in many cases are not undertaken as genuine pieces of investigatory science. Consequently they can lack a means for making sense of what the collection of studies is saying. These reviews can be biased by the researcher and often lack rigour. Furthermore, the use of reviews of the available evidence to provide insights and guidance for intervention into operational needs of practitioners and policymakers has largely been of secondary importance. For practitioners, making sense of a mass of often-contradictory evidence has become progressively harder. The quality of evidence underpinning decision-making and action has been questioned, for inadequate or incomplete evidence seriously impedes policy formulation and implementation. In exploring ways in which evidence-informed management reviews might be achieved, the authors evaluate the process of systematic review used in the medical sciences. Over the last fifteen years, medical science has attempted to improve the review process by synthesizing research in a systematic, transparent, and reproducible manner with the twin aims of enhancing the knowledge base and informing policymaking and practice. This paper evaluates the extent to which the process of systematic review can be applied to the management field in order to produce a reliable knowledge stock and enhanced practice by developing context-sensitive research. The paper highlights the challenges in developing an appropriate methodology.},
  langid = {english}
}

@incollection{Wasylewicz2019,
  title = {Clinical Decision Support Systems},
  booktitle = {Fundamentals of Clinical Data Science},
  author = {Wasylewicz, A. T. M. and {Scheepers-Hoeks}, A. M. J. W.},
  editor = {Kubben, Pieter and Dumontier, Michel and Dekker, Andre},
  year = {2019},
  pages = {153--169},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-99713-1_11},
  urldate = {2025-03-07},
  abstract = {Clinical decision support (CDS) includes a variety of tools and interventions computerized as well as non- computerized. High-quality clinical decision support systems (CDSS), computerized CDS, are essential to achieve the full benefits of electronic health records and computerized physician order entry. A CDSS can take into account all data available in the EHR making it possible to notice changes outside the scope of the professional and notice changes specific for a certain patient, within normal limits. However, to use of CDSS in practice, it is important to understand the basic requirements of these systems.},
  isbn = {978-3-319-99713-1},
  langid = {english},
  keywords = {CDSS,Clinical data science,Clinical decision support systems,Validation},
  file = {/Users/jason.brunson/Zotero/storage/9ICQJSHN/Wasylewicz and Scheepers-Hoeks - 2019 - Clinical Decision Support Systems.pdf}
}

@article{Welch2013,
  title = {Clinical Decision Support for Genetically Guided Personalized Medicine: A Systematic Review},
  shorttitle = {Clinical Decision Support for Genetically Guided Personalized Medicine},
  author = {Welch, Brandon M and Kawamoto, Kensaku},
  year = {2013},
  month = mar,
  journal = {Journal of the American Medical Informatics Association},
  volume = {20},
  number = {2},
  pages = {388--400},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/amiajnl-2012-000892},
  urldate = {2021-03-15},
  langid = {english}
}

@inproceedings{Wess1994,
  title = {Using K-d Trees to Improve the Retrieval Step in Case-Based Reasoning},
  booktitle = {Topics in Case-Based Reasoning},
  author = {Wess, Stefan and Althoff, Klaus-Dieter and Derwand, Guido},
  editor = {Wess, Stefan and Althoff, Klaus-Dieter and Richter, Michael M.},
  year = {1994},
  pages = {167--181},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-58330-0_85},
  abstract = {Retrieval of cases is one important step within the case-based reasoning paradigm. We propose an improvement of this stage in the process model for finding most similar cases with an average effort of O[log2n], n number of cases. The basic idea of the algorithm is to use the heterogeneity of the search space for a density-based structuring and to employ this precomputed structure, a k- d tree, for efficient case retrieval according to a given similarity measure. Besides illustrating the basic idea, we present empirical results of a comparison of four different k- d tree generating strategies and introduce the notion of dynamic bounds which significantly reduce the retrieval effort. The presented approach is fully implemented and used within two case-based reasoning systems for classification and diagnostic tasks, Patdex and Inreca.},
  isbn = {978-3-540-48655-8},
  langid = {english},
  keywords = {Case Base,Conceptual Cluster,Dynamic Bound,Geometric Bound,Similar Case},
  file = {/Users/jason.brunson/Zotero/storage/FKQ4FBPG/Wess et al. - 1994 - Using k-d trees to improve the retrieval step in c.pdf}
}

@article{Wilcox2016,
  title = {Clinical Quality Registries Have the Potential to Drive Improvements in the Appropriateness of Care},
  author = {Wilcox, Nick and McNeil, John J},
  year = {2016},
  journal = {Medical Journal of Australia},
  volume = {205},
  number = {S10},
  pages = {S21-S26},
  issn = {1326-5377},
  doi = {10.5694/mja15.00921},
  urldate = {2025-03-07},
  abstract = {The provision of timely, relevant and reliable information on patient care to clinicians has been shown to drive improvements in health care quality. Well constructed clinical quality registries collect and report information on both the appropriateness of care (process) in keeping with clinical practice guidelines and the effectiveness of care (outcomes). Notwithstanding the successful establishment of several new registries and improvements in established registries, barriers persist for clinical groups wishing to improve the quality of information and level of participation in registries in Australia. To address these barriers, the Australian Commission on Safety and Quality in Health Care has developed the Framework for Australian Clinical Quality Registries. The Framework describes a mechanism by which government jurisdictions and private hospital groups can authorise and secure record-level data, within high priority clinical domains, to measure, monitor and report the appropriateness and effectiveness of health care. The provision of benchmarked information back to clinicians on the appropriateness and outcomes of care is expected to improve adherence to evidence-based practice and drive improvement in outcomes.},
  copyright = {{\copyright} 2016 AMPCo Pty Ltd. All rights reserved},
  langid = {english},
  keywords = {General medicine,Health services administration,Informatics and computers},
  file = {/Users/jason.brunson/Zotero/storage/TTYJAPQL/Wilcox and McNeil - 2016 - Clinical quality registries have the potential to .pdf;/Users/jason.brunson/Zotero/storage/AY4M9GQA/mja15.html}
}

@inproceedings{Xing2002,
  title = {Distance Metric Learning with Application to Clustering with Side-Information},
  booktitle = {Advances in Neural Information Processing Systems 15 (NIPS 2002)},
  author = {Xing, Eric P. and Jordan, Michael and Russell, Stuart and Ng, Andrew Y.},
  year = {2002},
  volume = {15},
  publisher = {MIT Press},
  address = {Vancouver, BC, Canada},
  urldate = {2022-09-20},
  abstract = {Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many ``plausible'' ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider ``similar.'' For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, , learns a distance metric over if desired, dissimilar) pairs of points in that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance.},
  file = {/Users/jason.brunson/Zotero/storage/32TBCFCA/Xing et al. - 2002 - Distance Metric Learning with Application to Clust.pdf}
}

@phdthesis{Yang2006,
  title = {Distance Metric Learning: A Comprehensive Survey},
  author = {Yang, Liu},
  year = {2006},
  month = may,
  address = {Department of Computer Science and Engineering},
  urldate = {2022-09-20},
  abstract = {Many machine learning algorithms, such as K Nearest Neighbor (KNN), heav- ily rely on the distance metric for the input data patterns. Distance Metric learning is to learn a distance metric for the input space of data from a given collection of pair of similar/dissimilar points that preserves the distance relation among the training data. In recent years, many studies have demonstrated, both empirically and theoretically, that a learned metric can significantly improve the performance in classification, clustering and retrieval tasks. This paper surveys the field of dis- tance metric learning from a principle perspective, and includes a broad selection of recent work. In particular, distance metric learning is reviewed under different learning conditions: supervised learning versus unsupervised learning, learning in a global sense versus in a local sense; and the distance matrix based on linear kernel versus nonlinear kernel. In addition, this paper discusses a number of techniques that is central to distance metric learning, including convex programming, posi- tive semi-definite programming, kernel learning, dimension reduction, K Nearest Neighbor, large margin classification, and graph-based approaches.},
  langid = {english},
  school = {Michigan State University}
}

@preamble{ "\providecommand{\noopsort}[1]{} " }
